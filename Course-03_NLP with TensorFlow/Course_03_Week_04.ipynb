{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course_03_Week_04.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jbRqF2gQ0joT",
        "rJDYEKEX4Mpp",
        "s2tuwg0hARHU",
        "s6wKxbfa1IMr",
        "vMso6lYaHe77",
        "AFBHSr7evREe",
        "r4JUQz9uvwqA",
        "UfBh2Rzewsp8",
        "-2DglOt2y2Ht"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWsyDJuNhBB3",
        "colab_type": "text"
      },
      "source": [
        "#Course_03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD9eNZ0suVvf",
        "colab_type": "text"
      },
      "source": [
        "Natural Language Processing in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbRqF2gQ0joT",
        "colab_type": "text"
      },
      "source": [
        "##Week 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJDYEKEX4Mpp",
        "colab_type": "text"
      },
      "source": [
        "###Predicting Text Problem -- Introduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHKbqlXB2rBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj6I3IuL2lIi",
        "colab_type": "code",
        "outputId": "bbaeebc9-4908-4984-c1df-be7b95518732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPgrDfBD0kvV",
        "colab_type": "code",
        "outputId": "da674d52-4ba2-4c1b-a328-d6ab771e040d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "data = 'In the town of Athy one Jeremy Lanigan \\n Battered Away .... \\n Srijeet is great'\n",
        "corpus = data.lower().split('\\n')\n",
        "print(corpus)\n",
        "print(type(corpus))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['in the town of athy one jeremy lanigan ', ' battered away .... ', ' srijeet is great']\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7fA3yc12ztN",
        "colab_type": "code",
        "outputId": "f5c8d6b9-8d3e-44f6-b961-84b1313efdf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index)+1\n",
        "print(total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bKoY7Y03ji5",
        "colab_type": "code",
        "outputId": "09df3622-b1b9-43e5-97bc-d5fa45cc444c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'athy': 5,\n",
              " 'away': 10,\n",
              " 'battered': 9,\n",
              " 'great': 13,\n",
              " 'in': 1,\n",
              " 'is': 12,\n",
              " 'jeremy': 7,\n",
              " 'lanigan': 8,\n",
              " 'of': 4,\n",
              " 'one': 6,\n",
              " 'srijeet': 11,\n",
              " 'the': 2,\n",
              " 'town': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh5XrWLj4YJR",
        "colab_type": "text"
      },
      "source": [
        "Now converting this corpus to Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkhyGm1g3rsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = []\n",
        "\n",
        "# go through all the lines one-by-one\n",
        "for line in corpus:\n",
        "  #create a token_list for the line --covert line from string to list\n",
        "  # it returns a list of tokens(list of numbers)\n",
        "  # So take only the first elemnet as we have only one line \n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  #print(token_list)\n",
        "  for i in range(1,len(token_list)):\n",
        "    #print(i)\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    #print(n_gram_sequence)\n",
        "    input_sequence.append(n_gram_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDyZjFf6wve",
        "colab_type": "code",
        "outputId": "a21fe13f-5a6b-4352-931a-219921d88270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(input_sequence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7, 8], [9, 10], [11, 12], [11, 12, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exfU_VNZ8SeN",
        "colab_type": "code",
        "outputId": "f453b138-0885-4ad3-8163-50535c9d9c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Now lets find the longes sequence in the corpus :\n",
        "max_sequence_len = max([len(x) for x in input_sequence])\n",
        "\n",
        "\n",
        "# now lets pad all the sequences to this length :\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "input_sequences = np.array(pad_sequences(input_sequence , maxlen = max_sequence_len, padding = 'pre'))\n",
        "print(input_sequences)\n",
        "print(input_sequences.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  1  2]\n",
            " [ 0  0  0  0  0  1  2  3]\n",
            " [ 0  0  0  0  1  2  3  4]\n",
            " [ 0  0  0  1  2  3  4  5]\n",
            " [ 0  0  1  2  3  4  5  6]\n",
            " [ 0  1  2  3  4  5  6  7]\n",
            " [ 1  2  3  4  5  6  7  8]\n",
            " [ 0  0  0  0  0  0  9 10]\n",
            " [ 0  0  0  0  0  0 11 12]\n",
            " [ 0  0  0  0  0 11 12 13]]\n",
            "(10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uUNUtR292Kq",
        "colab_type": "code",
        "outputId": "0bcc1599-a4dd-42be-bd00-3159560868b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# So now we will have all col except last as X and the last col is the prediction :\n",
        "\n",
        "Xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:,-1]\n",
        "print(Xs.shape)\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 7)\n",
            "[ 2  3  4  5  6  7  8 10 12 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb3jBsCF-A0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One hot encoding of the labels ;\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes = total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2tuwg0hARHU",
        "colab_type": "text"
      },
      "source": [
        "### Text Prediction with relatively Large Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQaJAnVAVJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LG1gRKUAaSc",
        "colab_type": "code",
        "outputId": "8183eb35-9885-46e3-8fdb-b3d27e4377af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uH_GPdIApEA",
        "colab_type": "code",
        "outputId": "8a81a28b-25af-47d3-bf07-b915f867484e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Data is complete line from a poetry and each line is sepatated using a comma :\n",
        "\n",
        "data = \"FROM fairest creatures we desire increase,That thereby beautys rose might never die,But as the riper should by time decease,His tender heir might bear his memory,But thou contracted to thine own bright eyes,Feedst thy lightst flame with self-substantial fuel,Making a famine where abundance lies,Thyself thy foe, to thy sweet self too cruel\"\n",
        "\n",
        "corpus = data.lower().split(',')\n",
        "\n",
        "print(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from fairest creatures we desire increase', 'that thereby beautys rose might never die', 'but as the riper should by time decease', 'his tender heir might bear his memory', 'but thou contracted to thine own bright eyes', 'feedst thy lightst flame with self-substantial fuel', 'making a famine where abundance lies', 'thyself thy foe', ' to thy sweet self too cruel']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9k1UibhBTz5",
        "colab_type": "code",
        "outputId": "29810b62-9489-43f2-a4f6-623d21068d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Now lets trainin our Tokenizer on this data :\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))\n",
        "print(type(word_index))\n",
        "#print(word_index[:10])\n",
        "word_index['bright']\n",
        "\n",
        "total_words = len(word_index) + 1\n",
        "print(\"Total Words : \",total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52\n",
            "<class 'dict'>\n",
            "Total Words :  53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7AeFa3NFqWN",
        "colab_type": "text"
      },
      "source": [
        "This is Just for understanding :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lOdumJOCkoF",
        "colab_type": "code",
        "outputId": "a34ca886-015c-493b-f1ca-a7e1f27a0931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "input_sequence = []\n",
        "\n",
        "for line in corpus:\n",
        "  sequence = tokenizer.texts_to_sequences([line])\n",
        "  sequence = sequence[0]\n",
        "  print(sequence)\n",
        "  print('\\n')\n",
        "  for i in range(1,len(sequence)):\n",
        "    temp = sequence[:i+1]\n",
        "    print(f'input data tokenized list {i} is : {temp}')\n",
        "    input_sequence.append(temp)\n",
        "  \n",
        "  print(\"\\nFinal Clubbed Output is :\",input_sequence)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 8, 9, 10, 11, 12]\n",
            "\n",
            "\n",
            "input data tokenized list 1 is : [7, 8]\n",
            "input data tokenized list 2 is : [7, 8, 9]\n",
            "input data tokenized list 3 is : [7, 8, 9, 10]\n",
            "input data tokenized list 4 is : [7, 8, 9, 10, 11]\n",
            "input data tokenized list 5 is : [7, 8, 9, 10, 11, 12]\n",
            "\n",
            "Final Clubbed Output is : [[7, 8], [7, 8, 9], [7, 8, 9, 10], [7, 8, 9, 10, 11], [7, 8, 9, 10, 11, 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHyX6Xu5FtjX",
        "colab_type": "text"
      },
      "source": [
        "Now Lets creat the inpput for the entire corpus :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DejbTG6zDwPc",
        "colab_type": "code",
        "outputId": "336183c5-decf-4464-a7a0-bbf553088143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "input_sequence = []\n",
        "\n",
        "for line in corpus:\n",
        "  sequence = tokenizer.texts_to_sequences([line])\n",
        "  sequence = sequence[0]\n",
        "  print(sequence)\n",
        "  for i in range(1,len(sequence)):\n",
        "    temp = sequence[:i+1]\n",
        "    input_sequence.append(temp)\n",
        "\n",
        "print(len(input_sequence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 8, 9, 10, 11, 12]\n",
            "[13, 14, 15, 16, 2, 17, 18]\n",
            "[3, 19, 20, 21, 22, 23, 24, 25]\n",
            "[4, 26, 27, 2, 28, 4, 29]\n",
            "[3, 30, 31, 5, 32, 33, 34, 35]\n",
            "[36, 1, 37, 38, 39, 6, 40, 41]\n",
            "[42, 43, 44, 45, 46, 47]\n",
            "[48, 1, 49]\n",
            "[5, 1, 50, 6, 51, 52]\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN2FeynTGCrn",
        "colab_type": "text"
      },
      "source": [
        "Now we need to pad the input sequence as they are of different lengths . But For that decide the maxlen :\n",
        "\n",
        "It must be equal to the longest chain in the input sequence :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7lJeK5ZF3ar",
        "colab_type": "code",
        "outputId": "1a763990-37fb-4540-b154-c7ca15623a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_length = max([len(x) for x in input_sequence])\n",
        "print(max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBXf_bRZGmAf",
        "colab_type": "text"
      },
      "source": [
        "So now lets do the padding :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjJqWIXuGg6w",
        "colab_type": "code",
        "outputId": "b93523c2-f72c-4fd8-be65-e5a783493612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_input_sequence = pad_sequences(input_sequence , maxlen =  max_length , padding = 'pre')\n",
        "\n",
        "print(padded_input_sequence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  7  8]\n",
            " [ 0  0  0  0  0  7  8  9]\n",
            " [ 0  0  0  0  7  8  9 10]\n",
            " [ 0  0  0  7  8  9 10 11]\n",
            " [ 0  0  7  8  9 10 11 12]\n",
            " [ 0  0  0  0  0  0 13 14]\n",
            " [ 0  0  0  0  0 13 14 15]\n",
            " [ 0  0  0  0 13 14 15 16]\n",
            " [ 0  0  0 13 14 15 16  2]\n",
            " [ 0  0 13 14 15 16  2 17]\n",
            " [ 0 13 14 15 16  2 17 18]\n",
            " [ 0  0  0  0  0  0  3 19]\n",
            " [ 0  0  0  0  0  3 19 20]\n",
            " [ 0  0  0  0  3 19 20 21]\n",
            " [ 0  0  0  3 19 20 21 22]\n",
            " [ 0  0  3 19 20 21 22 23]\n",
            " [ 0  3 19 20 21 22 23 24]\n",
            " [ 3 19 20 21 22 23 24 25]\n",
            " [ 0  0  0  0  0  0  4 26]\n",
            " [ 0  0  0  0  0  4 26 27]\n",
            " [ 0  0  0  0  4 26 27  2]\n",
            " [ 0  0  0  4 26 27  2 28]\n",
            " [ 0  0  4 26 27  2 28  4]\n",
            " [ 0  4 26 27  2 28  4 29]\n",
            " [ 0  0  0  0  0  0  3 30]\n",
            " [ 0  0  0  0  0  3 30 31]\n",
            " [ 0  0  0  0  3 30 31  5]\n",
            " [ 0  0  0  3 30 31  5 32]\n",
            " [ 0  0  3 30 31  5 32 33]\n",
            " [ 0  3 30 31  5 32 33 34]\n",
            " [ 3 30 31  5 32 33 34 35]\n",
            " [ 0  0  0  0  0  0 36  1]\n",
            " [ 0  0  0  0  0 36  1 37]\n",
            " [ 0  0  0  0 36  1 37 38]\n",
            " [ 0  0  0 36  1 37 38 39]\n",
            " [ 0  0 36  1 37 38 39  6]\n",
            " [ 0 36  1 37 38 39  6 40]\n",
            " [36  1 37 38 39  6 40 41]\n",
            " [ 0  0  0  0  0  0 42 43]\n",
            " [ 0  0  0  0  0 42 43 44]\n",
            " [ 0  0  0  0 42 43 44 45]\n",
            " [ 0  0  0 42 43 44 45 46]\n",
            " [ 0  0 42 43 44 45 46 47]\n",
            " [ 0  0  0  0  0  0 48  1]\n",
            " [ 0  0  0  0  0 48  1 49]\n",
            " [ 0  0  0  0  0  0  5  1]\n",
            " [ 0  0  0  0  0  5  1 50]\n",
            " [ 0  0  0  0  5  1 50  6]\n",
            " [ 0  0  0  5  1 50  6 51]\n",
            " [ 0  0  5  1 50  6 51 52]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NiligEHtWf",
        "colab_type": "text"
      },
      "source": [
        "Now its time to create the Xs and Ys that is the inputs and outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOOHMPgSHeNs",
        "colab_type": "code",
        "outputId": "a2bf6170-f291-4b3b-b202-4377d814bd68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        }
      },
      "source": [
        "Xs = padded_input_sequence[:,:-1]\n",
        "ys = padded_input_sequence[:,-1]\n",
        "print(type(Xs))\n",
        "print(type(ys))\n",
        "print(Xs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[[ 0  0  0  0  0  0  7]\n",
            " [ 0  0  0  0  0  7  8]\n",
            " [ 0  0  0  0  7  8  9]\n",
            " [ 0  0  0  7  8  9 10]\n",
            " [ 0  0  7  8  9 10 11]\n",
            " [ 0  0  0  0  0  0 13]\n",
            " [ 0  0  0  0  0 13 14]\n",
            " [ 0  0  0  0 13 14 15]\n",
            " [ 0  0  0 13 14 15 16]\n",
            " [ 0  0 13 14 15 16  2]\n",
            " [ 0 13 14 15 16  2 17]\n",
            " [ 0  0  0  0  0  0  3]\n",
            " [ 0  0  0  0  0  3 19]\n",
            " [ 0  0  0  0  3 19 20]\n",
            " [ 0  0  0  3 19 20 21]\n",
            " [ 0  0  3 19 20 21 22]\n",
            " [ 0  3 19 20 21 22 23]\n",
            " [ 3 19 20 21 22 23 24]\n",
            " [ 0  0  0  0  0  0  4]\n",
            " [ 0  0  0  0  0  4 26]\n",
            " [ 0  0  0  0  4 26 27]\n",
            " [ 0  0  0  4 26 27  2]\n",
            " [ 0  0  4 26 27  2 28]\n",
            " [ 0  4 26 27  2 28  4]\n",
            " [ 0  0  0  0  0  0  3]\n",
            " [ 0  0  0  0  0  3 30]\n",
            " [ 0  0  0  0  3 30 31]\n",
            " [ 0  0  0  3 30 31  5]\n",
            " [ 0  0  3 30 31  5 32]\n",
            " [ 0  3 30 31  5 32 33]\n",
            " [ 3 30 31  5 32 33 34]\n",
            " [ 0  0  0  0  0  0 36]\n",
            " [ 0  0  0  0  0 36  1]\n",
            " [ 0  0  0  0 36  1 37]\n",
            " [ 0  0  0 36  1 37 38]\n",
            " [ 0  0 36  1 37 38 39]\n",
            " [ 0 36  1 37 38 39  6]\n",
            " [36  1 37 38 39  6 40]\n",
            " [ 0  0  0  0  0  0 42]\n",
            " [ 0  0  0  0  0 42 43]\n",
            " [ 0  0  0  0 42 43 44]\n",
            " [ 0  0  0 42 43 44 45]\n",
            " [ 0  0 42 43 44 45 46]\n",
            " [ 0  0  0  0  0  0 48]\n",
            " [ 0  0  0  0  0 48  1]\n",
            " [ 0  0  0  0  0  0  5]\n",
            " [ 0  0  0  0  0  5  1]\n",
            " [ 0  0  0  0  5  1 50]\n",
            " [ 0  0  0  5  1 50  6]\n",
            " [ 0  0  5  1 50  6 51]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79WDiPjibCiA",
        "colab_type": "text"
      },
      "source": [
        "But we need to convert the output token into categorial class :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tpg0WlDbMr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_number_words = len(word_index)\n",
        "ys = tf.keras.utils.to_categorical(ys , num_classes = total_number_words +1) #+1 is to take  care of the OOV token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JJ1NwbTf-ep",
        "colab_type": "text"
      },
      "source": [
        "Now Lets Analyze one Example :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2cx03RgCJR",
        "colab_type": "code",
        "outputId": "9ef41a60-f971-4158-bef1-5f10b6c55754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "print('\\n\\n ---------------------- Take one Example-----------------------------------\\n\\n')\n",
        "\n",
        "print('\\nThe Statemenr from the corpus----->',corpus[0])\n",
        "\n",
        "print(\"\\n\\nToken for the word from is ------> \",tokenizer.word_index['from'])\n",
        "print(\"Token for the word fairest is ------> \",tokenizer.word_index['fairest'])\n",
        "print(\"Token for the word creatures  is ------> \",tokenizer.word_index['creatures'])\n",
        "print(\"Token for the word we is ------> \",tokenizer.word_index['we'])\n",
        "print(\"Token for the word desire  is ------> \",tokenizer.word_index['desire'])\n",
        "print(\"Token for the word increase  is ------> \",tokenizer.word_index['increase'])\n",
        "\n",
        "\n",
        "print('\\nThe Padded Sequence for the text is---->',padded_input_sequence[4])\n",
        "\n",
        "print('\\nThe Corresponding Xs\\n',Xs[4])\n",
        "\n",
        "print('\\nThe Corresponding ys\\n',ys[4])\n",
        "# note it has 53 dimentional output  and 1 @ the 12th position as per the sequence\n",
        "\n",
        "# you can check the word_index dictionary to confirm the tokens:\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " ---------------------- Take one Example-----------------------------------\n",
            "\n",
            "\n",
            "\n",
            "The Statemenr from the corpus-----> from fairest creatures we desire increase\n",
            "\n",
            "\n",
            "Token for the word from is ------>  7\n",
            "Token for the word fairest is ------>  8\n",
            "Token for the word creatures  is ------>  9\n",
            "Token for the word we is ------>  10\n",
            "Token for the word desire  is ------>  11\n",
            "Token for the word increase  is ------>  12\n",
            "\n",
            "The Padded Sequence for the text is----> [ 0  0  7  8  9 10 11 12]\n",
            "\n",
            "The Corresponding Xs\n",
            " [ 0  0  7  8  9 10 11]\n",
            "\n",
            "The Corresponding ys\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOCbBc1jaFgf",
        "colab_type": "text"
      },
      "source": [
        "Its time now for Model Development :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5du0S_QYH-UD",
        "colab_type": "code",
        "outputId": "f9110443-1b37-4690-8ebc-00c215b26eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "input_dim = (len(word_index)+1)\n",
        "embedding_dim = 64\n",
        "inputlength = (max_length - 1 ) # as we have taken ys out of it \n",
        "no_of_outputs = total_number_words +1  # as during ys categorical creation we kept one for the OOV token also \n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding( input_dim , embedding_dim ,input_length = inputlength),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
        "                                    #tf.keras.layers.Dense(len(word_index) , activation = 'relu'),\n",
        "                                    tf.keras.layers.Dense(len(word_index)+1,activation = 'softmax')\n",
        "])\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(Xs , ys , epochs = 1500 , verbose = 1 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f0ff4dceb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0ff4dceb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f0ff4dceb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0ff4dceb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f0ff4dcebf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0ff4dcebf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f0ff4dcebf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0ff4dcebf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f0ff4dceb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0ff4dceb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f0ff4dceb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0ff4dceb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f0ff4dcebf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0ff4dcebf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f0ff4dcebf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0ff4dcebf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 50 samples\n",
            "Epoch 1/1500\n",
            "50/50 [==============================] - 1s 17ms/sample - loss: 3.9705 - accuracy: 0.0400\n",
            "Epoch 2/1500\n",
            "50/50 [==============================] - 0s 381us/sample - loss: 3.9649 - accuracy: 0.0600\n",
            "Epoch 3/1500\n",
            "50/50 [==============================] - 0s 267us/sample - loss: 3.9608 - accuracy: 0.1200\n",
            "Epoch 4/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 3.9563 - accuracy: 0.0800\n",
            "Epoch 5/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 3.9519 - accuracy: 0.0600\n",
            "Epoch 6/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 3.9476 - accuracy: 0.0800\n",
            "Epoch 7/1500\n",
            "50/50 [==============================] - 0s 281us/sample - loss: 3.9432 - accuracy: 0.0800\n",
            "Epoch 8/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 3.9382 - accuracy: 0.1000\n",
            "Epoch 9/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 3.9334 - accuracy: 0.1000\n",
            "Epoch 10/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 3.9281 - accuracy: 0.1000\n",
            "Epoch 11/1500\n",
            "50/50 [==============================] - 0s 275us/sample - loss: 3.9221 - accuracy: 0.1000\n",
            "Epoch 12/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 3.9165 - accuracy: 0.1000\n",
            "Epoch 13/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 3.9092 - accuracy: 0.1000\n",
            "Epoch 14/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 3.9024 - accuracy: 0.1000\n",
            "Epoch 15/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 3.8945 - accuracy: 0.1000\n",
            "Epoch 16/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 3.8857 - accuracy: 0.1000\n",
            "Epoch 17/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 3.8764 - accuracy: 0.1000\n",
            "Epoch 18/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 3.8664 - accuracy: 0.1000\n",
            "Epoch 19/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 3.8550 - accuracy: 0.1000\n",
            "Epoch 20/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 3.8426 - accuracy: 0.1000\n",
            "Epoch 21/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 3.8282 - accuracy: 0.1000\n",
            "Epoch 22/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 3.8130 - accuracy: 0.1000\n",
            "Epoch 23/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 3.7950 - accuracy: 0.1000\n",
            "Epoch 24/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 3.7778 - accuracy: 0.1000\n",
            "Epoch 25/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 3.7590 - accuracy: 0.1000\n",
            "Epoch 26/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 3.7367 - accuracy: 0.1000\n",
            "Epoch 27/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 3.7104 - accuracy: 0.1000\n",
            "Epoch 28/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 3.6872 - accuracy: 0.1000\n",
            "Epoch 29/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 3.6627 - accuracy: 0.1000\n",
            "Epoch 30/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 3.6373 - accuracy: 0.1000\n",
            "Epoch 31/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 3.6061 - accuracy: 0.1000\n",
            "Epoch 32/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 3.5824 - accuracy: 0.1000\n",
            "Epoch 33/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 3.5541 - accuracy: 0.1000\n",
            "Epoch 34/1500\n",
            "50/50 [==============================] - 0s 289us/sample - loss: 3.5274 - accuracy: 0.1000\n",
            "Epoch 35/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 3.4995 - accuracy: 0.1400\n",
            "Epoch 36/1500\n",
            "50/50 [==============================] - 0s 383us/sample - loss: 3.4697 - accuracy: 0.1400\n",
            "Epoch 37/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 3.4368 - accuracy: 0.1600\n",
            "Epoch 38/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 3.4047 - accuracy: 0.2000\n",
            "Epoch 39/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 3.3692 - accuracy: 0.2200\n",
            "Epoch 40/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 3.3332 - accuracy: 0.2200\n",
            "Epoch 41/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 3.2957 - accuracy: 0.2200\n",
            "Epoch 42/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 3.2565 - accuracy: 0.2600\n",
            "Epoch 43/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 3.2161 - accuracy: 0.2800\n",
            "Epoch 44/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 3.1740 - accuracy: 0.3000\n",
            "Epoch 45/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 3.1310 - accuracy: 0.2800\n",
            "Epoch 46/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 3.0845 - accuracy: 0.3000\n",
            "Epoch 47/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 3.0387 - accuracy: 0.3000\n",
            "Epoch 48/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 2.9912 - accuracy: 0.3200\n",
            "Epoch 49/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 2.9439 - accuracy: 0.3400\n",
            "Epoch 50/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 2.8942 - accuracy: 0.3600\n",
            "Epoch 51/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 2.8438 - accuracy: 0.3600\n",
            "Epoch 52/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 2.7912 - accuracy: 0.3600\n",
            "Epoch 53/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 2.7420 - accuracy: 0.3400\n",
            "Epoch 54/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 2.6889 - accuracy: 0.4000\n",
            "Epoch 55/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 2.6387 - accuracy: 0.4000\n",
            "Epoch 56/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 2.5874 - accuracy: 0.3800\n",
            "Epoch 57/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 2.5364 - accuracy: 0.4400\n",
            "Epoch 58/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 2.4872 - accuracy: 0.4400\n",
            "Epoch 59/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 2.4399 - accuracy: 0.4400\n",
            "Epoch 60/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 2.3907 - accuracy: 0.4800\n",
            "Epoch 61/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 2.3429 - accuracy: 0.4600\n",
            "Epoch 62/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 2.2969 - accuracy: 0.4400\n",
            "Epoch 63/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 2.2479 - accuracy: 0.4400\n",
            "Epoch 64/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 2.2039 - accuracy: 0.4400\n",
            "Epoch 65/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 2.1595 - accuracy: 0.4600\n",
            "Epoch 66/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 2.1172 - accuracy: 0.4800\n",
            "Epoch 67/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 2.0766 - accuracy: 0.4800\n",
            "Epoch 68/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 2.0351 - accuracy: 0.4800\n",
            "Epoch 69/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 1.9937 - accuracy: 0.5200\n",
            "Epoch 70/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 1.9554 - accuracy: 0.5400\n",
            "Epoch 71/1500\n",
            "50/50 [==============================] - 0s 389us/sample - loss: 1.9166 - accuracy: 0.5600\n",
            "Epoch 72/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 1.8791 - accuracy: 0.5800\n",
            "Epoch 73/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 1.8438 - accuracy: 0.6000\n",
            "Epoch 74/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 1.8079 - accuracy: 0.6200\n",
            "Epoch 75/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 1.7758 - accuracy: 0.6600\n",
            "Epoch 76/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 1.7423 - accuracy: 0.6600\n",
            "Epoch 77/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 1.7119 - accuracy: 0.6400\n",
            "Epoch 78/1500\n",
            "50/50 [==============================] - 0s 387us/sample - loss: 1.6811 - accuracy: 0.6600\n",
            "Epoch 79/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 1.6521 - accuracy: 0.6400\n",
            "Epoch 80/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 1.6218 - accuracy: 0.6400\n",
            "Epoch 81/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 1.5954 - accuracy: 0.6600\n",
            "Epoch 82/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 1.5665 - accuracy: 0.6600\n",
            "Epoch 83/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 1.5415 - accuracy: 0.6800\n",
            "Epoch 84/1500\n",
            "50/50 [==============================] - 0s 284us/sample - loss: 1.5167 - accuracy: 0.7200\n",
            "Epoch 85/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 1.4906 - accuracy: 0.7000\n",
            "Epoch 86/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 1.4670 - accuracy: 0.7200\n",
            "Epoch 87/1500\n",
            "50/50 [==============================] - 0s 288us/sample - loss: 1.4422 - accuracy: 0.7000\n",
            "Epoch 88/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 1.4187 - accuracy: 0.7200\n",
            "Epoch 89/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 1.3966 - accuracy: 0.7400\n",
            "Epoch 90/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 1.3751 - accuracy: 0.7600\n",
            "Epoch 91/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 1.3524 - accuracy: 0.7400\n",
            "Epoch 92/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 1.3318 - accuracy: 0.7400\n",
            "Epoch 93/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 1.3118 - accuracy: 0.7800\n",
            "Epoch 94/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 1.2909 - accuracy: 0.8000\n",
            "Epoch 95/1500\n",
            "50/50 [==============================] - 0s 381us/sample - loss: 1.2710 - accuracy: 0.8200\n",
            "Epoch 96/1500\n",
            "50/50 [==============================] - 0s 427us/sample - loss: 1.2508 - accuracy: 0.8200\n",
            "Epoch 97/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 1.2321 - accuracy: 0.8000\n",
            "Epoch 98/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 1.2143 - accuracy: 0.8200\n",
            "Epoch 99/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 1.1951 - accuracy: 0.8200\n",
            "Epoch 100/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 1.1771 - accuracy: 0.8400\n",
            "Epoch 101/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 1.1602 - accuracy: 0.8400\n",
            "Epoch 102/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 1.1421 - accuracy: 0.8600\n",
            "Epoch 103/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 1.1255 - accuracy: 0.8600\n",
            "Epoch 104/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 1.1082 - accuracy: 0.8600\n",
            "Epoch 105/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 1.0920 - accuracy: 0.8600\n",
            "Epoch 106/1500\n",
            "50/50 [==============================] - 0s 401us/sample - loss: 1.0775 - accuracy: 0.8800\n",
            "Epoch 107/1500\n",
            "50/50 [==============================] - 0s 396us/sample - loss: 1.0617 - accuracy: 0.8600\n",
            "Epoch 108/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 1.0454 - accuracy: 0.8800\n",
            "Epoch 109/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 1.0302 - accuracy: 0.8600\n",
            "Epoch 110/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 1.0165 - accuracy: 0.8600\n",
            "Epoch 111/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 1.0015 - accuracy: 0.8800\n",
            "Epoch 112/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.9863 - accuracy: 0.9000\n",
            "Epoch 113/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.9728 - accuracy: 0.9000\n",
            "Epoch 114/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.9592 - accuracy: 0.9000\n",
            "Epoch 115/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.9444 - accuracy: 0.9200\n",
            "Epoch 116/1500\n",
            "50/50 [==============================] - 0s 378us/sample - loss: 0.9335 - accuracy: 0.9000\n",
            "Epoch 117/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.9180 - accuracy: 0.9200\n",
            "Epoch 118/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 0.9062 - accuracy: 0.9000\n",
            "Epoch 119/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.8940 - accuracy: 0.9200\n",
            "Epoch 120/1500\n",
            "50/50 [==============================] - 0s 417us/sample - loss: 0.8813 - accuracy: 0.9200\n",
            "Epoch 121/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.8679 - accuracy: 0.9200\n",
            "Epoch 122/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.8564 - accuracy: 0.9200\n",
            "Epoch 123/1500\n",
            "50/50 [==============================] - 0s 363us/sample - loss: 0.8443 - accuracy: 0.9200\n",
            "Epoch 124/1500\n",
            "50/50 [==============================] - 0s 392us/sample - loss: 0.8331 - accuracy: 0.9200\n",
            "Epoch 125/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.8227 - accuracy: 0.9200\n",
            "Epoch 126/1500\n",
            "50/50 [==============================] - 0s 368us/sample - loss: 0.8103 - accuracy: 0.9200\n",
            "Epoch 127/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.7996 - accuracy: 0.9400\n",
            "Epoch 128/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.7882 - accuracy: 0.9400\n",
            "Epoch 129/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.7773 - accuracy: 0.9400\n",
            "Epoch 130/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.7659 - accuracy: 0.9600\n",
            "Epoch 131/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.7559 - accuracy: 0.9600\n",
            "Epoch 132/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.7454 - accuracy: 0.9600\n",
            "Epoch 133/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.7367 - accuracy: 0.9600\n",
            "Epoch 134/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.7237 - accuracy: 0.9600\n",
            "Epoch 135/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.7154 - accuracy: 0.9600\n",
            "Epoch 136/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.7071 - accuracy: 0.9600\n",
            "Epoch 137/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.6976 - accuracy: 0.9600\n",
            "Epoch 138/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.6854 - accuracy: 0.9600\n",
            "Epoch 139/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.6773 - accuracy: 0.9600\n",
            "Epoch 140/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.6676 - accuracy: 0.9600\n",
            "Epoch 141/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.6579 - accuracy: 0.9600\n",
            "Epoch 142/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.6488 - accuracy: 0.9600\n",
            "Epoch 143/1500\n",
            "50/50 [==============================] - 0s 358us/sample - loss: 0.6399 - accuracy: 0.9800\n",
            "Epoch 144/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.6320 - accuracy: 0.9800\n",
            "Epoch 145/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.6223 - accuracy: 0.9800\n",
            "Epoch 146/1500\n",
            "50/50 [==============================] - 0s 277us/sample - loss: 0.6140 - accuracy: 0.9800\n",
            "Epoch 147/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.6057 - accuracy: 0.9800\n",
            "Epoch 148/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.5981 - accuracy: 0.9800\n",
            "Epoch 149/1500\n",
            "50/50 [==============================] - 0s 371us/sample - loss: 0.5902 - accuracy: 0.9800\n",
            "Epoch 150/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.5830 - accuracy: 0.9800\n",
            "Epoch 151/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.5761 - accuracy: 0.9600\n",
            "Epoch 152/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.5678 - accuracy: 0.9800\n",
            "Epoch 153/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.5601 - accuracy: 0.9600\n",
            "Epoch 154/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.5525 - accuracy: 0.9800\n",
            "Epoch 155/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.5456 - accuracy: 0.9800\n",
            "Epoch 156/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.5390 - accuracy: 0.9800\n",
            "Epoch 157/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.5319 - accuracy: 0.9800\n",
            "Epoch 158/1500\n",
            "50/50 [==============================] - 0s 380us/sample - loss: 0.5255 - accuracy: 0.9800\n",
            "Epoch 159/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.5186 - accuracy: 0.9800\n",
            "Epoch 160/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.5129 - accuracy: 0.9800\n",
            "Epoch 161/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.5068 - accuracy: 0.9800\n",
            "Epoch 162/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.4995 - accuracy: 0.9800\n",
            "Epoch 163/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.4938 - accuracy: 0.9800\n",
            "Epoch 164/1500\n",
            "50/50 [==============================] - 0s 397us/sample - loss: 0.4876 - accuracy: 0.9800\n",
            "Epoch 165/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.4820 - accuracy: 0.9600\n",
            "Epoch 166/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.4756 - accuracy: 0.9800\n",
            "Epoch 167/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.4704 - accuracy: 0.9800\n",
            "Epoch 168/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.4652 - accuracy: 0.9800\n",
            "Epoch 169/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.4595 - accuracy: 0.9800\n",
            "Epoch 170/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.4541 - accuracy: 0.9800\n",
            "Epoch 171/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.4490 - accuracy: 0.9800\n",
            "Epoch 172/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.4434 - accuracy: 0.9800\n",
            "Epoch 173/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.4386 - accuracy: 0.9800\n",
            "Epoch 174/1500\n",
            "50/50 [==============================] - 0s 358us/sample - loss: 0.4333 - accuracy: 0.9800\n",
            "Epoch 175/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.4289 - accuracy: 0.9800\n",
            "Epoch 176/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.4238 - accuracy: 0.9800\n",
            "Epoch 177/1500\n",
            "50/50 [==============================] - 0s 265us/sample - loss: 0.4192 - accuracy: 0.9800\n",
            "Epoch 178/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.4147 - accuracy: 0.9800\n",
            "Epoch 179/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.4102 - accuracy: 0.9800\n",
            "Epoch 180/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.4055 - accuracy: 0.9800\n",
            "Epoch 181/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.4007 - accuracy: 0.9800\n",
            "Epoch 182/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.3966 - accuracy: 0.9800\n",
            "Epoch 183/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.3922 - accuracy: 0.9800\n",
            "Epoch 184/1500\n",
            "50/50 [==============================] - 0s 429us/sample - loss: 0.3879 - accuracy: 0.9800\n",
            "Epoch 185/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.3843 - accuracy: 0.9800\n",
            "Epoch 186/1500\n",
            "50/50 [==============================] - 0s 363us/sample - loss: 0.3799 - accuracy: 0.9800\n",
            "Epoch 187/1500\n",
            "50/50 [==============================] - 0s 368us/sample - loss: 0.3758 - accuracy: 0.9800\n",
            "Epoch 188/1500\n",
            "50/50 [==============================] - 0s 378us/sample - loss: 0.3717 - accuracy: 0.9800\n",
            "Epoch 189/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.3681 - accuracy: 0.9800\n",
            "Epoch 190/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.3646 - accuracy: 0.9800\n",
            "Epoch 191/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.3607 - accuracy: 0.9800\n",
            "Epoch 192/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.3569 - accuracy: 0.9800\n",
            "Epoch 193/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.3532 - accuracy: 0.9800\n",
            "Epoch 194/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.3494 - accuracy: 0.9800\n",
            "Epoch 195/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.3462 - accuracy: 0.9800\n",
            "Epoch 196/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.3427 - accuracy: 0.9800\n",
            "Epoch 197/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.3390 - accuracy: 0.9800\n",
            "Epoch 198/1500\n",
            "50/50 [==============================] - 0s 368us/sample - loss: 0.3361 - accuracy: 0.9800\n",
            "Epoch 199/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.3322 - accuracy: 0.9800\n",
            "Epoch 200/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.3289 - accuracy: 0.9800\n",
            "Epoch 201/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.3259 - accuracy: 0.9800\n",
            "Epoch 202/1500\n",
            "50/50 [==============================] - 0s 376us/sample - loss: 0.3227 - accuracy: 0.9800\n",
            "Epoch 203/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.3195 - accuracy: 0.9800\n",
            "Epoch 204/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.3159 - accuracy: 0.9800\n",
            "Epoch 205/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.3132 - accuracy: 0.9800\n",
            "Epoch 206/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.3101 - accuracy: 0.9800\n",
            "Epoch 207/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.3077 - accuracy: 0.9800\n",
            "Epoch 208/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.3043 - accuracy: 0.9800\n",
            "Epoch 209/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.3014 - accuracy: 0.9800\n",
            "Epoch 210/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.2991 - accuracy: 0.9800\n",
            "Epoch 211/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.2956 - accuracy: 0.9800\n",
            "Epoch 212/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.2928 - accuracy: 0.9800\n",
            "Epoch 213/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.2901 - accuracy: 0.9800\n",
            "Epoch 214/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.2877 - accuracy: 0.9600\n",
            "Epoch 215/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.2849 - accuracy: 0.9800\n",
            "Epoch 216/1500\n",
            "50/50 [==============================] - 0s 382us/sample - loss: 0.2823 - accuracy: 0.9800\n",
            "Epoch 217/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.2797 - accuracy: 0.9800\n",
            "Epoch 218/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.2774 - accuracy: 0.9800\n",
            "Epoch 219/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.2749 - accuracy: 0.9800\n",
            "Epoch 220/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.2726 - accuracy: 0.9800\n",
            "Epoch 221/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.2698 - accuracy: 0.9800\n",
            "Epoch 222/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.2673 - accuracy: 0.9800\n",
            "Epoch 223/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.2652 - accuracy: 0.9800\n",
            "Epoch 224/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.2632 - accuracy: 0.9600\n",
            "Epoch 225/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.2607 - accuracy: 0.9800\n",
            "Epoch 226/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.2583 - accuracy: 0.9800\n",
            "Epoch 227/1500\n",
            "50/50 [==============================] - 0s 383us/sample - loss: 0.2570 - accuracy: 0.9800\n",
            "Epoch 228/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.2544 - accuracy: 0.9800\n",
            "Epoch 229/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.2517 - accuracy: 0.9800\n",
            "Epoch 230/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.2495 - accuracy: 0.9800\n",
            "Epoch 231/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.2479 - accuracy: 0.9800\n",
            "Epoch 232/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.2462 - accuracy: 0.9800\n",
            "Epoch 233/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.2437 - accuracy: 0.9800\n",
            "Epoch 234/1500\n",
            "50/50 [==============================] - 0s 373us/sample - loss: 0.2418 - accuracy: 0.9800\n",
            "Epoch 235/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.2400 - accuracy: 0.9800\n",
            "Epoch 236/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.2381 - accuracy: 0.9800\n",
            "Epoch 237/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.2355 - accuracy: 0.9800\n",
            "Epoch 238/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.2342 - accuracy: 0.9800\n",
            "Epoch 239/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.2322 - accuracy: 0.9800\n",
            "Epoch 240/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.2304 - accuracy: 0.9800\n",
            "Epoch 241/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.2285 - accuracy: 0.9800\n",
            "Epoch 242/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.2265 - accuracy: 0.9800\n",
            "Epoch 243/1500\n",
            "50/50 [==============================] - 0s 280us/sample - loss: 0.2248 - accuracy: 0.9800\n",
            "Epoch 244/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.2230 - accuracy: 0.9800\n",
            "Epoch 245/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.2215 - accuracy: 0.9800\n",
            "Epoch 246/1500\n",
            "50/50 [==============================] - 0s 371us/sample - loss: 0.2198 - accuracy: 0.9800\n",
            "Epoch 247/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.2180 - accuracy: 0.9800\n",
            "Epoch 248/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.2164 - accuracy: 0.9800\n",
            "Epoch 249/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.2148 - accuracy: 0.9800\n",
            "Epoch 250/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.2131 - accuracy: 0.9800\n",
            "Epoch 251/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.2114 - accuracy: 0.9800\n",
            "Epoch 252/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.2097 - accuracy: 0.9800\n",
            "Epoch 253/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.2088 - accuracy: 0.9800\n",
            "Epoch 254/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.2075 - accuracy: 0.9600\n",
            "Epoch 255/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.2056 - accuracy: 0.9800\n",
            "Epoch 256/1500\n",
            "50/50 [==============================] - 0s 474us/sample - loss: 0.2041 - accuracy: 0.9600\n",
            "Epoch 257/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.2026 - accuracy: 0.9800\n",
            "Epoch 258/1500\n",
            "50/50 [==============================] - 0s 407us/sample - loss: 0.2013 - accuracy: 0.9600\n",
            "Epoch 259/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.1996 - accuracy: 0.9800\n",
            "Epoch 260/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.1982 - accuracy: 0.9800\n",
            "Epoch 261/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.1967 - accuracy: 0.9800\n",
            "Epoch 262/1500\n",
            "50/50 [==============================] - 0s 360us/sample - loss: 0.1955 - accuracy: 0.9800\n",
            "Epoch 263/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.1945 - accuracy: 0.9800\n",
            "Epoch 264/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.1929 - accuracy: 0.9800\n",
            "Epoch 265/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.1913 - accuracy: 0.9800\n",
            "Epoch 266/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.1903 - accuracy: 0.9800\n",
            "Epoch 267/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.1891 - accuracy: 0.9800\n",
            "Epoch 268/1500\n",
            "50/50 [==============================] - 0s 283us/sample - loss: 0.1879 - accuracy: 0.9800\n",
            "Epoch 269/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.1864 - accuracy: 0.9800\n",
            "Epoch 270/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.1850 - accuracy: 0.9800\n",
            "Epoch 271/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.1839 - accuracy: 0.9800\n",
            "Epoch 272/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.1829 - accuracy: 0.9600\n",
            "Epoch 273/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.1815 - accuracy: 0.9800\n",
            "Epoch 274/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.1806 - accuracy: 0.9800\n",
            "Epoch 275/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.1794 - accuracy: 0.9800\n",
            "Epoch 276/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.1782 - accuracy: 0.9800\n",
            "Epoch 277/1500\n",
            "50/50 [==============================] - 0s 288us/sample - loss: 0.1769 - accuracy: 0.9800\n",
            "Epoch 278/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.1758 - accuracy: 0.9800\n",
            "Epoch 279/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.1747 - accuracy: 0.9800\n",
            "Epoch 280/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.1738 - accuracy: 0.9800\n",
            "Epoch 281/1500\n",
            "50/50 [==============================] - 0s 389us/sample - loss: 0.1726 - accuracy: 0.9800\n",
            "Epoch 282/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.1714 - accuracy: 0.9800\n",
            "Epoch 283/1500\n",
            "50/50 [==============================] - 0s 379us/sample - loss: 0.1704 - accuracy: 0.9800\n",
            "Epoch 284/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.1693 - accuracy: 0.9800\n",
            "Epoch 285/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.1685 - accuracy: 0.9800\n",
            "Epoch 286/1500\n",
            "50/50 [==============================] - 0s 388us/sample - loss: 0.1675 - accuracy: 0.9800\n",
            "Epoch 287/1500\n",
            "50/50 [==============================] - 0s 418us/sample - loss: 0.1665 - accuracy: 0.9800\n",
            "Epoch 288/1500\n",
            "50/50 [==============================] - 0s 387us/sample - loss: 0.1654 - accuracy: 0.9800\n",
            "Epoch 289/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.1645 - accuracy: 0.9800\n",
            "Epoch 290/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.1637 - accuracy: 0.9800\n",
            "Epoch 291/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.1627 - accuracy: 0.9800\n",
            "Epoch 292/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.1619 - accuracy: 0.9800\n",
            "Epoch 293/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.1606 - accuracy: 0.9800\n",
            "Epoch 294/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.1596 - accuracy: 0.9800\n",
            "Epoch 295/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.1589 - accuracy: 0.9800\n",
            "Epoch 296/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.1579 - accuracy: 0.9800\n",
            "Epoch 297/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.1571 - accuracy: 0.9800\n",
            "Epoch 298/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.1562 - accuracy: 0.9800\n",
            "Epoch 299/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.1554 - accuracy: 0.9800\n",
            "Epoch 300/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.1548 - accuracy: 0.9800\n",
            "Epoch 301/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.1538 - accuracy: 0.9800\n",
            "Epoch 302/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.1531 - accuracy: 0.9800\n",
            "Epoch 303/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.1519 - accuracy: 0.9800\n",
            "Epoch 304/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.1512 - accuracy: 0.9800\n",
            "Epoch 305/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.1505 - accuracy: 0.9800\n",
            "Epoch 306/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.1496 - accuracy: 0.9800\n",
            "Epoch 307/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.1489 - accuracy: 0.9800\n",
            "Epoch 308/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.1478 - accuracy: 0.9800\n",
            "Epoch 309/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.1470 - accuracy: 0.9800\n",
            "Epoch 310/1500\n",
            "50/50 [==============================] - 0s 394us/sample - loss: 0.1462 - accuracy: 0.9800\n",
            "Epoch 311/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.1454 - accuracy: 0.9800\n",
            "Epoch 312/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.1445 - accuracy: 0.9800\n",
            "Epoch 313/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.1439 - accuracy: 0.9800\n",
            "Epoch 314/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.1429 - accuracy: 0.9800\n",
            "Epoch 315/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.1426 - accuracy: 0.9800\n",
            "Epoch 316/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.1414 - accuracy: 0.9800\n",
            "Epoch 317/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.1406 - accuracy: 0.9800\n",
            "Epoch 318/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.1401 - accuracy: 0.9600\n",
            "Epoch 319/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.1392 - accuracy: 0.9800\n",
            "Epoch 320/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.1385 - accuracy: 0.9800\n",
            "Epoch 321/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.1377 - accuracy: 0.9800\n",
            "Epoch 322/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.1372 - accuracy: 0.9800\n",
            "Epoch 323/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.1364 - accuracy: 0.9800\n",
            "Epoch 324/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.1357 - accuracy: 0.9800\n",
            "Epoch 325/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.1349 - accuracy: 0.9800\n",
            "Epoch 326/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.1342 - accuracy: 0.9800\n",
            "Epoch 327/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.1335 - accuracy: 0.9800\n",
            "Epoch 328/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.1329 - accuracy: 0.9800\n",
            "Epoch 329/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.1323 - accuracy: 0.9800\n",
            "Epoch 330/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.1317 - accuracy: 0.9800\n",
            "Epoch 331/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.1310 - accuracy: 0.9800\n",
            "Epoch 332/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.1305 - accuracy: 0.9800\n",
            "Epoch 333/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.1298 - accuracy: 0.9800\n",
            "Epoch 334/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.1291 - accuracy: 0.9800\n",
            "Epoch 335/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.1285 - accuracy: 0.9800\n",
            "Epoch 336/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.1279 - accuracy: 0.9800\n",
            "Epoch 337/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.1276 - accuracy: 0.9600\n",
            "Epoch 338/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.1268 - accuracy: 0.9800\n",
            "Epoch 339/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.1260 - accuracy: 0.9800\n",
            "Epoch 340/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.1255 - accuracy: 0.9800\n",
            "Epoch 341/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.1250 - accuracy: 0.9800\n",
            "Epoch 342/1500\n",
            "50/50 [==============================] - 0s 372us/sample - loss: 0.1245 - accuracy: 0.9800\n",
            "Epoch 343/1500\n",
            "50/50 [==============================] - 0s 378us/sample - loss: 0.1239 - accuracy: 0.9800\n",
            "Epoch 344/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.1232 - accuracy: 0.9800\n",
            "Epoch 345/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.1227 - accuracy: 0.9800\n",
            "Epoch 346/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.1220 - accuracy: 0.9800\n",
            "Epoch 347/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.1215 - accuracy: 0.9800\n",
            "Epoch 348/1500\n",
            "50/50 [==============================] - 0s 383us/sample - loss: 0.1209 - accuracy: 0.9800\n",
            "Epoch 349/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.1204 - accuracy: 0.9800\n",
            "Epoch 350/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.1199 - accuracy: 0.9800\n",
            "Epoch 351/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.1193 - accuracy: 0.9800\n",
            "Epoch 352/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.1188 - accuracy: 0.9800\n",
            "Epoch 353/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.1182 - accuracy: 0.9800\n",
            "Epoch 354/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.1178 - accuracy: 0.9800\n",
            "Epoch 355/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.1173 - accuracy: 0.9800\n",
            "Epoch 356/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.1169 - accuracy: 0.9800\n",
            "Epoch 357/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.1162 - accuracy: 0.9800\n",
            "Epoch 358/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.1158 - accuracy: 0.9800\n",
            "Epoch 359/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.1151 - accuracy: 0.9800\n",
            "Epoch 360/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.1148 - accuracy: 0.9800\n",
            "Epoch 361/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.1143 - accuracy: 0.9800\n",
            "Epoch 362/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.1137 - accuracy: 0.9800\n",
            "Epoch 363/1500\n",
            "50/50 [==============================] - 0s 361us/sample - loss: 0.1131 - accuracy: 0.9800\n",
            "Epoch 364/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.1129 - accuracy: 0.9800\n",
            "Epoch 365/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.1123 - accuracy: 0.9800\n",
            "Epoch 366/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.1119 - accuracy: 0.9800\n",
            "Epoch 367/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.1113 - accuracy: 0.9800\n",
            "Epoch 368/1500\n",
            "50/50 [==============================] - 0s 271us/sample - loss: 0.1108 - accuracy: 0.9800\n",
            "Epoch 369/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.1103 - accuracy: 0.9800\n",
            "Epoch 370/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.1099 - accuracy: 0.9800\n",
            "Epoch 371/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.1094 - accuracy: 0.9800\n",
            "Epoch 372/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.1092 - accuracy: 0.9800\n",
            "Epoch 373/1500\n",
            "50/50 [==============================] - 0s 284us/sample - loss: 0.1085 - accuracy: 0.9800\n",
            "Epoch 374/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.1081 - accuracy: 0.9800\n",
            "Epoch 375/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.1076 - accuracy: 0.9800\n",
            "Epoch 376/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.1073 - accuracy: 0.9800\n",
            "Epoch 377/1500\n",
            "50/50 [==============================] - 0s 277us/sample - loss: 0.1068 - accuracy: 0.9800\n",
            "Epoch 378/1500\n",
            "50/50 [==============================] - 0s 272us/sample - loss: 0.1064 - accuracy: 0.9800\n",
            "Epoch 379/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.1058 - accuracy: 0.9800\n",
            "Epoch 380/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.1054 - accuracy: 0.9800\n",
            "Epoch 381/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.1049 - accuracy: 0.9800\n",
            "Epoch 382/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.1045 - accuracy: 0.9800\n",
            "Epoch 383/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.1041 - accuracy: 0.9800\n",
            "Epoch 384/1500\n",
            "50/50 [==============================] - 0s 388us/sample - loss: 0.1037 - accuracy: 0.9800\n",
            "Epoch 385/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.1034 - accuracy: 0.9800\n",
            "Epoch 386/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.1029 - accuracy: 0.9800\n",
            "Epoch 387/1500\n",
            "50/50 [==============================] - 0s 384us/sample - loss: 0.1027 - accuracy: 0.9800\n",
            "Epoch 388/1500\n",
            "50/50 [==============================] - 0s 408us/sample - loss: 0.1022 - accuracy: 0.9800\n",
            "Epoch 389/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.1018 - accuracy: 0.9600\n",
            "Epoch 390/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.1013 - accuracy: 0.9800\n",
            "Epoch 391/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.1010 - accuracy: 0.9800\n",
            "Epoch 392/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.1007 - accuracy: 0.9600\n",
            "Epoch 393/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.1002 - accuracy: 0.9800\n",
            "Epoch 394/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0997 - accuracy: 0.9800\n",
            "Epoch 395/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0997 - accuracy: 0.9800\n",
            "Epoch 396/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0991 - accuracy: 0.9800\n",
            "Epoch 397/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0988 - accuracy: 0.9800\n",
            "Epoch 398/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0982 - accuracy: 0.9800\n",
            "Epoch 399/1500\n",
            "50/50 [==============================] - 0s 447us/sample - loss: 0.0979 - accuracy: 0.9800\n",
            "Epoch 400/1500\n",
            "50/50 [==============================] - 0s 360us/sample - loss: 0.0976 - accuracy: 0.9800\n",
            "Epoch 401/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0974 - accuracy: 0.9800\n",
            "Epoch 402/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0969 - accuracy: 0.9800\n",
            "Epoch 403/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0968 - accuracy: 0.9600\n",
            "Epoch 404/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0961 - accuracy: 0.9800\n",
            "Epoch 405/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0958 - accuracy: 0.9800\n",
            "Epoch 406/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0956 - accuracy: 0.9600\n",
            "Epoch 407/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0952 - accuracy: 0.9800\n",
            "Epoch 408/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0947 - accuracy: 0.9800\n",
            "Epoch 409/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0946 - accuracy: 0.9600\n",
            "Epoch 410/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0941 - accuracy: 0.9800\n",
            "Epoch 411/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0938 - accuracy: 0.9800\n",
            "Epoch 412/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0934 - accuracy: 0.9800\n",
            "Epoch 413/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0931 - accuracy: 0.9800\n",
            "Epoch 414/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0927 - accuracy: 0.9800\n",
            "Epoch 415/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0925 - accuracy: 0.9800\n",
            "Epoch 416/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0922 - accuracy: 0.9800\n",
            "Epoch 417/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0918 - accuracy: 0.9800\n",
            "Epoch 418/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0916 - accuracy: 0.9800\n",
            "Epoch 419/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0912 - accuracy: 0.9800\n",
            "Epoch 420/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0911 - accuracy: 0.9800\n",
            "Epoch 421/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0906 - accuracy: 0.9800\n",
            "Epoch 422/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0903 - accuracy: 0.9800\n",
            "Epoch 423/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0901 - accuracy: 0.9800\n",
            "Epoch 424/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0897 - accuracy: 0.9800\n",
            "Epoch 425/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0894 - accuracy: 0.9800\n",
            "Epoch 426/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0891 - accuracy: 0.9800\n",
            "Epoch 427/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0887 - accuracy: 0.9800\n",
            "Epoch 428/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.0887 - accuracy: 0.9800\n",
            "Epoch 429/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0881 - accuracy: 0.9800\n",
            "Epoch 430/1500\n",
            "50/50 [==============================] - 0s 290us/sample - loss: 0.0880 - accuracy: 0.9800\n",
            "Epoch 431/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0877 - accuracy: 0.9800\n",
            "Epoch 432/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0872 - accuracy: 0.9800\n",
            "Epoch 433/1500\n",
            "50/50 [==============================] - 0s 430us/sample - loss: 0.0869 - accuracy: 0.9800\n",
            "Epoch 434/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0868 - accuracy: 0.9800\n",
            "Epoch 435/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.0864 - accuracy: 0.9800\n",
            "Epoch 436/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0861 - accuracy: 0.9800\n",
            "Epoch 437/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0858 - accuracy: 0.9800\n",
            "Epoch 438/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0855 - accuracy: 0.9800\n",
            "Epoch 439/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0853 - accuracy: 0.9800\n",
            "Epoch 440/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0850 - accuracy: 0.9800\n",
            "Epoch 441/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0848 - accuracy: 0.9800\n",
            "Epoch 442/1500\n",
            "50/50 [==============================] - 0s 361us/sample - loss: 0.0845 - accuracy: 0.9800\n",
            "Epoch 443/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0842 - accuracy: 0.9800\n",
            "Epoch 444/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0841 - accuracy: 0.9800\n",
            "Epoch 445/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0837 - accuracy: 0.9800\n",
            "Epoch 446/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0834 - accuracy: 0.9800\n",
            "Epoch 447/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0833 - accuracy: 0.9800\n",
            "Epoch 448/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0829 - accuracy: 0.9800\n",
            "Epoch 449/1500\n",
            "50/50 [==============================] - 0s 380us/sample - loss: 0.0826 - accuracy: 0.9800\n",
            "Epoch 450/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0825 - accuracy: 0.9800\n",
            "Epoch 451/1500\n",
            "50/50 [==============================] - 0s 376us/sample - loss: 0.0823 - accuracy: 0.9800\n",
            "Epoch 452/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0821 - accuracy: 0.9800\n",
            "Epoch 453/1500\n",
            "50/50 [==============================] - 0s 411us/sample - loss: 0.0818 - accuracy: 0.9800\n",
            "Epoch 454/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0815 - accuracy: 0.9800\n",
            "Epoch 455/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0812 - accuracy: 0.9800\n",
            "Epoch 456/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0810 - accuracy: 0.9800\n",
            "Epoch 457/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0807 - accuracy: 0.9800\n",
            "Epoch 458/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0806 - accuracy: 0.9800\n",
            "Epoch 459/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0802 - accuracy: 0.9800\n",
            "Epoch 460/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0801 - accuracy: 0.9800\n",
            "Epoch 461/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0798 - accuracy: 0.9800\n",
            "Epoch 462/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0795 - accuracy: 0.9800\n",
            "Epoch 463/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0793 - accuracy: 0.9800\n",
            "Epoch 464/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0792 - accuracy: 0.9800\n",
            "Epoch 465/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.0789 - accuracy: 0.9800\n",
            "Epoch 466/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0786 - accuracy: 0.9800\n",
            "Epoch 467/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0785 - accuracy: 0.9800\n",
            "Epoch 468/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0781 - accuracy: 0.9800\n",
            "Epoch 469/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0779 - accuracy: 0.9800\n",
            "Epoch 470/1500\n",
            "50/50 [==============================] - 0s 288us/sample - loss: 0.0777 - accuracy: 0.9800\n",
            "Epoch 471/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0775 - accuracy: 0.9800\n",
            "Epoch 472/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0773 - accuracy: 0.9800\n",
            "Epoch 473/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0773 - accuracy: 0.9800\n",
            "Epoch 474/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0770 - accuracy: 0.9800\n",
            "Epoch 475/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0768 - accuracy: 0.9800\n",
            "Epoch 476/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0765 - accuracy: 0.9800\n",
            "Epoch 477/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0765 - accuracy: 0.9800\n",
            "Epoch 478/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 0.0760 - accuracy: 0.9800\n",
            "Epoch 479/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0758 - accuracy: 0.9800\n",
            "Epoch 480/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0756 - accuracy: 0.9800\n",
            "Epoch 481/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0754 - accuracy: 0.9800\n",
            "Epoch 482/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0751 - accuracy: 0.9800\n",
            "Epoch 483/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0749 - accuracy: 0.9800\n",
            "Epoch 484/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0747 - accuracy: 0.9800\n",
            "Epoch 485/1500\n",
            "50/50 [==============================] - 0s 360us/sample - loss: 0.0745 - accuracy: 0.9800\n",
            "Epoch 486/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0743 - accuracy: 0.9800\n",
            "Epoch 487/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0741 - accuracy: 0.9800\n",
            "Epoch 488/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0739 - accuracy: 0.9800\n",
            "Epoch 489/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0738 - accuracy: 0.9800\n",
            "Epoch 490/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0738 - accuracy: 0.9800\n",
            "Epoch 491/1500\n",
            "50/50 [==============================] - 0s 262us/sample - loss: 0.0734 - accuracy: 0.9800\n",
            "Epoch 492/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0733 - accuracy: 0.9800\n",
            "Epoch 493/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0731 - accuracy: 0.9800\n",
            "Epoch 494/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0729 - accuracy: 0.9800\n",
            "Epoch 495/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0727 - accuracy: 0.9800\n",
            "Epoch 496/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0725 - accuracy: 0.9800\n",
            "Epoch 497/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0726 - accuracy: 0.9800\n",
            "Epoch 498/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0722 - accuracy: 0.9800\n",
            "Epoch 499/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0720 - accuracy: 0.9800\n",
            "Epoch 500/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0718 - accuracy: 0.9800\n",
            "Epoch 501/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0716 - accuracy: 0.9800\n",
            "Epoch 502/1500\n",
            "50/50 [==============================] - 0s 278us/sample - loss: 0.0714 - accuracy: 0.9800\n",
            "Epoch 503/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0712 - accuracy: 0.9800\n",
            "Epoch 504/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0711 - accuracy: 0.9800\n",
            "Epoch 505/1500\n",
            "50/50 [==============================] - 0s 360us/sample - loss: 0.0708 - accuracy: 0.9800\n",
            "Epoch 506/1500\n",
            "50/50 [==============================] - 0s 289us/sample - loss: 0.0707 - accuracy: 0.9800\n",
            "Epoch 507/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0704 - accuracy: 0.9800\n",
            "Epoch 508/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0703 - accuracy: 0.9800\n",
            "Epoch 509/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0701 - accuracy: 0.9800\n",
            "Epoch 510/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0699 - accuracy: 0.9800\n",
            "Epoch 511/1500\n",
            "50/50 [==============================] - 0s 272us/sample - loss: 0.0697 - accuracy: 0.9800\n",
            "Epoch 512/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0696 - accuracy: 0.9800\n",
            "Epoch 513/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0695 - accuracy: 0.9800\n",
            "Epoch 514/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0696 - accuracy: 0.9800\n",
            "Epoch 515/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0692 - accuracy: 0.9800\n",
            "Epoch 516/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0691 - accuracy: 0.9800\n",
            "Epoch 517/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0689 - accuracy: 0.9800\n",
            "Epoch 518/1500\n",
            "50/50 [==============================] - 0s 278us/sample - loss: 0.0689 - accuracy: 0.9800\n",
            "Epoch 519/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0685 - accuracy: 0.9800\n",
            "Epoch 520/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0683 - accuracy: 0.9800\n",
            "Epoch 521/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0681 - accuracy: 0.9800\n",
            "Epoch 522/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0681 - accuracy: 0.9800\n",
            "Epoch 523/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0679 - accuracy: 0.9800\n",
            "Epoch 524/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0677 - accuracy: 0.9800\n",
            "Epoch 525/1500\n",
            "50/50 [==============================] - 0s 400us/sample - loss: 0.0677 - accuracy: 0.9800\n",
            "Epoch 526/1500\n",
            "50/50 [==============================] - 0s 407us/sample - loss: 0.0674 - accuracy: 0.9800\n",
            "Epoch 527/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0672 - accuracy: 0.9800\n",
            "Epoch 528/1500\n",
            "50/50 [==============================] - 0s 391us/sample - loss: 0.0671 - accuracy: 0.9800\n",
            "Epoch 529/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0669 - accuracy: 0.9800\n",
            "Epoch 530/1500\n",
            "50/50 [==============================] - 0s 405us/sample - loss: 0.0667 - accuracy: 0.9800\n",
            "Epoch 531/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0665 - accuracy: 0.9800\n",
            "Epoch 532/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0666 - accuracy: 0.9800\n",
            "Epoch 533/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0664 - accuracy: 0.9800\n",
            "Epoch 534/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0662 - accuracy: 0.9800\n",
            "Epoch 535/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0661 - accuracy: 0.9800\n",
            "Epoch 536/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0658 - accuracy: 0.9800\n",
            "Epoch 537/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0657 - accuracy: 0.9800\n",
            "Epoch 538/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0654 - accuracy: 0.9800\n",
            "Epoch 539/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0653 - accuracy: 0.9800\n",
            "Epoch 540/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0651 - accuracy: 0.9800\n",
            "Epoch 541/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0650 - accuracy: 0.9800\n",
            "Epoch 542/1500\n",
            "50/50 [==============================] - 0s 289us/sample - loss: 0.0649 - accuracy: 0.9800\n",
            "Epoch 543/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0648 - accuracy: 0.9600\n",
            "Epoch 544/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0647 - accuracy: 0.9800\n",
            "Epoch 545/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0644 - accuracy: 0.9800\n",
            "Epoch 546/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0643 - accuracy: 0.9800\n",
            "Epoch 547/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0641 - accuracy: 0.9800\n",
            "Epoch 548/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0643 - accuracy: 0.9800\n",
            "Epoch 549/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0639 - accuracy: 0.9800\n",
            "Epoch 550/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0638 - accuracy: 0.9800\n",
            "Epoch 551/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0637 - accuracy: 0.9800\n",
            "Epoch 552/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0637 - accuracy: 0.9800\n",
            "Epoch 553/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0634 - accuracy: 0.9800\n",
            "Epoch 554/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0633 - accuracy: 0.9800\n",
            "Epoch 555/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0632 - accuracy: 0.9800\n",
            "Epoch 556/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0631 - accuracy: 0.9800\n",
            "Epoch 557/1500\n",
            "50/50 [==============================] - 0s 384us/sample - loss: 0.0629 - accuracy: 0.9800\n",
            "Epoch 558/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0627 - accuracy: 0.9800\n",
            "Epoch 559/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.0626 - accuracy: 0.9800\n",
            "Epoch 560/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0625 - accuracy: 0.9800\n",
            "Epoch 561/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0626 - accuracy: 0.9800\n",
            "Epoch 562/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0624 - accuracy: 0.9800\n",
            "Epoch 563/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0622 - accuracy: 0.9800\n",
            "Epoch 564/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0620 - accuracy: 0.9800\n",
            "Epoch 565/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0620 - accuracy: 0.9800\n",
            "Epoch 566/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0620 - accuracy: 0.9800\n",
            "Epoch 567/1500\n",
            "50/50 [==============================] - 0s 400us/sample - loss: 0.0618 - accuracy: 0.9800\n",
            "Epoch 568/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0615 - accuracy: 0.9800\n",
            "Epoch 569/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0614 - accuracy: 0.9800\n",
            "Epoch 570/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0613 - accuracy: 0.9800\n",
            "Epoch 571/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0613 - accuracy: 0.9800\n",
            "Epoch 572/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0610 - accuracy: 0.9800\n",
            "Epoch 573/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0609 - accuracy: 0.9800\n",
            "Epoch 574/1500\n",
            "50/50 [==============================] - 0s 390us/sample - loss: 0.0608 - accuracy: 0.9800\n",
            "Epoch 575/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0606 - accuracy: 0.9800\n",
            "Epoch 576/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0606 - accuracy: 0.9800\n",
            "Epoch 577/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0607 - accuracy: 0.9800\n",
            "Epoch 578/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0604 - accuracy: 0.9800\n",
            "Epoch 579/1500\n",
            "50/50 [==============================] - 0s 361us/sample - loss: 0.0604 - accuracy: 0.9800\n",
            "Epoch 580/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0601 - accuracy: 0.9800\n",
            "Epoch 581/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0600 - accuracy: 0.9800\n",
            "Epoch 582/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0599 - accuracy: 0.9800\n",
            "Epoch 583/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0597 - accuracy: 0.9800\n",
            "Epoch 584/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0597 - accuracy: 0.9800\n",
            "Epoch 585/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0595 - accuracy: 0.9800\n",
            "Epoch 586/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0594 - accuracy: 0.9800\n",
            "Epoch 587/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0593 - accuracy: 0.9800\n",
            "Epoch 588/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0592 - accuracy: 0.9800\n",
            "Epoch 589/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0591 - accuracy: 0.9800\n",
            "Epoch 590/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0591 - accuracy: 0.9800\n",
            "Epoch 591/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0589 - accuracy: 0.9800\n",
            "Epoch 592/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0588 - accuracy: 0.9800\n",
            "Epoch 593/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0588 - accuracy: 0.9800\n",
            "Epoch 594/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0585 - accuracy: 0.9800\n",
            "Epoch 595/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0585 - accuracy: 0.9800\n",
            "Epoch 596/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0583 - accuracy: 0.9800\n",
            "Epoch 597/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0584 - accuracy: 0.9800\n",
            "Epoch 598/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0583 - accuracy: 0.9800\n",
            "Epoch 599/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0581 - accuracy: 0.9800\n",
            "Epoch 600/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0579 - accuracy: 0.9800\n",
            "Epoch 601/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0578 - accuracy: 0.9800\n",
            "Epoch 602/1500\n",
            "50/50 [==============================] - 0s 388us/sample - loss: 0.0578 - accuracy: 0.9800\n",
            "Epoch 603/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0576 - accuracy: 0.9800\n",
            "Epoch 604/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0575 - accuracy: 0.9800\n",
            "Epoch 605/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0574 - accuracy: 0.9800\n",
            "Epoch 606/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0573 - accuracy: 0.9800\n",
            "Epoch 607/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0572 - accuracy: 0.9800\n",
            "Epoch 608/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0572 - accuracy: 0.9800\n",
            "Epoch 609/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0570 - accuracy: 0.9800\n",
            "Epoch 610/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0569 - accuracy: 0.9800\n",
            "Epoch 611/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0568 - accuracy: 0.9800\n",
            "Epoch 612/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0568 - accuracy: 0.9800\n",
            "Epoch 613/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0567 - accuracy: 0.9800\n",
            "Epoch 614/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0566 - accuracy: 0.9800\n",
            "Epoch 615/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0566 - accuracy: 0.9800\n",
            "Epoch 616/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0565 - accuracy: 0.9800\n",
            "Epoch 617/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0564 - accuracy: 0.9800\n",
            "Epoch 618/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0563 - accuracy: 0.9800\n",
            "Epoch 619/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0563 - accuracy: 0.9800\n",
            "Epoch 620/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0566 - accuracy: 0.9800\n",
            "Epoch 621/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0563 - accuracy: 0.9800\n",
            "Epoch 622/1500\n",
            "50/50 [==============================] - 0s 277us/sample - loss: 0.0562 - accuracy: 0.9800\n",
            "Epoch 623/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0562 - accuracy: 0.9800\n",
            "Epoch 624/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0560 - accuracy: 0.9800\n",
            "Epoch 625/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0559 - accuracy: 0.9800\n",
            "Epoch 626/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0558 - accuracy: 0.9800\n",
            "Epoch 627/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0558 - accuracy: 0.9800\n",
            "Epoch 628/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0556 - accuracy: 0.9800\n",
            "Epoch 629/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0556 - accuracy: 0.9800\n",
            "Epoch 630/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0553 - accuracy: 0.9800\n",
            "Epoch 631/1500\n",
            "50/50 [==============================] - 0s 285us/sample - loss: 0.0552 - accuracy: 0.9800\n",
            "Epoch 632/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0550 - accuracy: 0.9800\n",
            "Epoch 633/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.0548 - accuracy: 0.9800\n",
            "Epoch 634/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0548 - accuracy: 0.9800\n",
            "Epoch 635/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0550 - accuracy: 0.9800\n",
            "Epoch 636/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0547 - accuracy: 0.9800\n",
            "Epoch 637/1500\n",
            "50/50 [==============================] - 0s 390us/sample - loss: 0.0545 - accuracy: 0.9800\n",
            "Epoch 638/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0543 - accuracy: 0.9800\n",
            "Epoch 639/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0543 - accuracy: 0.9800\n",
            "Epoch 640/1500\n",
            "50/50 [==============================] - 0s 393us/sample - loss: 0.0542 - accuracy: 0.9800\n",
            "Epoch 641/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0542 - accuracy: 0.9800\n",
            "Epoch 642/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0540 - accuracy: 0.9800\n",
            "Epoch 643/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0539 - accuracy: 0.9800\n",
            "Epoch 644/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0539 - accuracy: 0.9800\n",
            "Epoch 645/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0538 - accuracy: 0.9800\n",
            "Epoch 646/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0537 - accuracy: 0.9800\n",
            "Epoch 647/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0539 - accuracy: 0.9800\n",
            "Epoch 648/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0536 - accuracy: 0.9800\n",
            "Epoch 649/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0536 - accuracy: 0.9800\n",
            "Epoch 650/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0536 - accuracy: 0.9800\n",
            "Epoch 651/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0533 - accuracy: 0.9800\n",
            "Epoch 652/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0533 - accuracy: 0.9800\n",
            "Epoch 653/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0532 - accuracy: 0.9800\n",
            "Epoch 654/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0531 - accuracy: 0.9800\n",
            "Epoch 655/1500\n",
            "50/50 [==============================] - 0s 363us/sample - loss: 0.0530 - accuracy: 0.9800\n",
            "Epoch 656/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0530 - accuracy: 0.9800\n",
            "Epoch 657/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0530 - accuracy: 0.9800\n",
            "Epoch 658/1500\n",
            "50/50 [==============================] - 0s 403us/sample - loss: 0.0527 - accuracy: 0.9800\n",
            "Epoch 659/1500\n",
            "50/50 [==============================] - 0s 363us/sample - loss: 0.0526 - accuracy: 0.9800\n",
            "Epoch 660/1500\n",
            "50/50 [==============================] - 0s 371us/sample - loss: 0.0526 - accuracy: 0.9800\n",
            "Epoch 661/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0526 - accuracy: 0.9800\n",
            "Epoch 662/1500\n",
            "50/50 [==============================] - 0s 393us/sample - loss: 0.0524 - accuracy: 0.9800\n",
            "Epoch 663/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0526 - accuracy: 0.9800\n",
            "Epoch 664/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0523 - accuracy: 0.9800\n",
            "Epoch 665/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0522 - accuracy: 0.9800\n",
            "Epoch 666/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0522 - accuracy: 0.9800\n",
            "Epoch 667/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0520 - accuracy: 0.9800\n",
            "Epoch 668/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0520 - accuracy: 0.9800\n",
            "Epoch 669/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0519 - accuracy: 0.9800\n",
            "Epoch 670/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0518 - accuracy: 0.9800\n",
            "Epoch 671/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0518 - accuracy: 0.9800\n",
            "Epoch 672/1500\n",
            "50/50 [==============================] - 0s 289us/sample - loss: 0.0517 - accuracy: 0.9800\n",
            "Epoch 673/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0520 - accuracy: 0.9800\n",
            "Epoch 674/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0517 - accuracy: 0.9800\n",
            "Epoch 675/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0516 - accuracy: 0.9800\n",
            "Epoch 676/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0517 - accuracy: 0.9800\n",
            "Epoch 677/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0515 - accuracy: 0.9800\n",
            "Epoch 678/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0514 - accuracy: 0.9800\n",
            "Epoch 679/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0513 - accuracy: 0.9800\n",
            "Epoch 680/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0512 - accuracy: 0.9800\n",
            "Epoch 681/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0512 - accuracy: 0.9800\n",
            "Epoch 682/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0511 - accuracy: 0.9800\n",
            "Epoch 683/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0510 - accuracy: 0.9800\n",
            "Epoch 684/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0509 - accuracy: 0.9800\n",
            "Epoch 685/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0509 - accuracy: 0.9800\n",
            "Epoch 686/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0508 - accuracy: 0.9800\n",
            "Epoch 687/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0507 - accuracy: 0.9800\n",
            "Epoch 688/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0507 - accuracy: 0.9800\n",
            "Epoch 689/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0505 - accuracy: 0.9800\n",
            "Epoch 690/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0505 - accuracy: 0.9800\n",
            "Epoch 691/1500\n",
            "50/50 [==============================] - 0s 399us/sample - loss: 0.0505 - accuracy: 0.9800\n",
            "Epoch 692/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 0.0503 - accuracy: 0.9800\n",
            "Epoch 693/1500\n",
            "50/50 [==============================] - 0s 382us/sample - loss: 0.0505 - accuracy: 0.9800\n",
            "Epoch 694/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0502 - accuracy: 0.9800\n",
            "Epoch 695/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0503 - accuracy: 0.9800\n",
            "Epoch 696/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0501 - accuracy: 0.9800\n",
            "Epoch 697/1500\n",
            "50/50 [==============================] - 0s 372us/sample - loss: 0.0500 - accuracy: 0.9800\n",
            "Epoch 698/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0499 - accuracy: 0.9800\n",
            "Epoch 699/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0499 - accuracy: 0.9800\n",
            "Epoch 700/1500\n",
            "50/50 [==============================] - 0s 284us/sample - loss: 0.0498 - accuracy: 0.9800\n",
            "Epoch 701/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0498 - accuracy: 0.9800\n",
            "Epoch 702/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0497 - accuracy: 0.9800\n",
            "Epoch 703/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0497 - accuracy: 0.9800\n",
            "Epoch 704/1500\n",
            "50/50 [==============================] - 0s 397us/sample - loss: 0.0497 - accuracy: 0.9800\n",
            "Epoch 705/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0496 - accuracy: 0.9800\n",
            "Epoch 706/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0496 - accuracy: 0.9800\n",
            "Epoch 707/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0496 - accuracy: 0.9800\n",
            "Epoch 708/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0495 - accuracy: 0.9800\n",
            "Epoch 709/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 0.0494 - accuracy: 0.9800\n",
            "Epoch 710/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0494 - accuracy: 0.9800\n",
            "Epoch 711/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0494 - accuracy: 0.9800\n",
            "Epoch 712/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0494 - accuracy: 0.9800\n",
            "Epoch 713/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0495 - accuracy: 0.9800\n",
            "Epoch 714/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0493 - accuracy: 0.9800\n",
            "Epoch 715/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0492 - accuracy: 0.9800\n",
            "Epoch 716/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0493 - accuracy: 0.9800\n",
            "Epoch 717/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.0491 - accuracy: 0.9800\n",
            "Epoch 718/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0491 - accuracy: 0.9800\n",
            "Epoch 719/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0488 - accuracy: 0.9800\n",
            "Epoch 720/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 0.0488 - accuracy: 0.9800\n",
            "Epoch 721/1500\n",
            "50/50 [==============================] - 0s 281us/sample - loss: 0.0486 - accuracy: 0.9800\n",
            "Epoch 722/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0486 - accuracy: 0.9800\n",
            "Epoch 723/1500\n",
            "50/50 [==============================] - 0s 272us/sample - loss: 0.0487 - accuracy: 0.9800\n",
            "Epoch 724/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0484 - accuracy: 0.9800\n",
            "Epoch 725/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0483 - accuracy: 0.9800\n",
            "Epoch 726/1500\n",
            "50/50 [==============================] - 0s 282us/sample - loss: 0.0484 - accuracy: 0.9800\n",
            "Epoch 727/1500\n",
            "50/50 [==============================] - 0s 268us/sample - loss: 0.0482 - accuracy: 0.9800\n",
            "Epoch 728/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0481 - accuracy: 0.9800\n",
            "Epoch 729/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0482 - accuracy: 0.9800\n",
            "Epoch 730/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.0480 - accuracy: 0.9800\n",
            "Epoch 731/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0479 - accuracy: 0.9800\n",
            "Epoch 732/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0479 - accuracy: 0.9800\n",
            "Epoch 733/1500\n",
            "50/50 [==============================] - 0s 383us/sample - loss: 0.0479 - accuracy: 0.9800\n",
            "Epoch 734/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0478 - accuracy: 0.9800\n",
            "Epoch 735/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0477 - accuracy: 0.9800\n",
            "Epoch 736/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0477 - accuracy: 0.9800\n",
            "Epoch 737/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0477 - accuracy: 0.9800\n",
            "Epoch 738/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0477 - accuracy: 0.9800\n",
            "Epoch 739/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0475 - accuracy: 0.9800\n",
            "Epoch 740/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0475 - accuracy: 0.9800\n",
            "Epoch 741/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0475 - accuracy: 0.9800\n",
            "Epoch 742/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0475 - accuracy: 0.9800\n",
            "Epoch 743/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.0474 - accuracy: 0.9800\n",
            "Epoch 744/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0472 - accuracy: 0.9800\n",
            "Epoch 745/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0472 - accuracy: 0.9800\n",
            "Epoch 746/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0471 - accuracy: 0.9800\n",
            "Epoch 747/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0471 - accuracy: 0.9800\n",
            "Epoch 748/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.0470 - accuracy: 0.9800\n",
            "Epoch 749/1500\n",
            "50/50 [==============================] - 0s 387us/sample - loss: 0.0470 - accuracy: 0.9800\n",
            "Epoch 750/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0470 - accuracy: 0.9800\n",
            "Epoch 751/1500\n",
            "50/50 [==============================] - 0s 386us/sample - loss: 0.0469 - accuracy: 0.9800\n",
            "Epoch 752/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0468 - accuracy: 0.9800\n",
            "Epoch 753/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0467 - accuracy: 0.9800\n",
            "Epoch 754/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0467 - accuracy: 0.9800\n",
            "Epoch 755/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0469 - accuracy: 0.9800\n",
            "Epoch 756/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0467 - accuracy: 0.9800\n",
            "Epoch 757/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0466 - accuracy: 0.9800\n",
            "Epoch 758/1500\n",
            "50/50 [==============================] - 0s 361us/sample - loss: 0.0466 - accuracy: 0.9800\n",
            "Epoch 759/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0465 - accuracy: 0.9800\n",
            "Epoch 760/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0465 - accuracy: 0.9800\n",
            "Epoch 761/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0464 - accuracy: 0.9800\n",
            "Epoch 762/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0464 - accuracy: 0.9800\n",
            "Epoch 763/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0464 - accuracy: 0.9800\n",
            "Epoch 764/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0462 - accuracy: 0.9800\n",
            "Epoch 765/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0462 - accuracy: 0.9800\n",
            "Epoch 766/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0461 - accuracy: 0.9800\n",
            "Epoch 767/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0461 - accuracy: 0.9800\n",
            "Epoch 768/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0460 - accuracy: 0.9800\n",
            "Epoch 769/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0460 - accuracy: 0.9800\n",
            "Epoch 770/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0459 - accuracy: 0.9800\n",
            "Epoch 771/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0458 - accuracy: 0.9800\n",
            "Epoch 772/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0459 - accuracy: 0.9800\n",
            "Epoch 773/1500\n",
            "50/50 [==============================] - 0s 380us/sample - loss: 0.0459 - accuracy: 0.9800\n",
            "Epoch 774/1500\n",
            "50/50 [==============================] - 0s 392us/sample - loss: 0.0459 - accuracy: 0.9800\n",
            "Epoch 775/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0460 - accuracy: 0.9800\n",
            "Epoch 776/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0458 - accuracy: 0.9800\n",
            "Epoch 777/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0459 - accuracy: 0.9800\n",
            "Epoch 778/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0457 - accuracy: 0.9800\n",
            "Epoch 779/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0456 - accuracy: 0.9800\n",
            "Epoch 780/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0456 - accuracy: 0.9800\n",
            "Epoch 781/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0455 - accuracy: 0.9800\n",
            "Epoch 782/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.0454 - accuracy: 0.9800\n",
            "Epoch 783/1500\n",
            "50/50 [==============================] - 0s 424us/sample - loss: 0.0454 - accuracy: 0.9800\n",
            "Epoch 784/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0455 - accuracy: 0.9800\n",
            "Epoch 785/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0453 - accuracy: 0.9800\n",
            "Epoch 786/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0453 - accuracy: 0.9800\n",
            "Epoch 787/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.0453 - accuracy: 0.9800\n",
            "Epoch 788/1500\n",
            "50/50 [==============================] - 0s 277us/sample - loss: 0.0453 - accuracy: 0.9800\n",
            "Epoch 789/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0451 - accuracy: 0.9800\n",
            "Epoch 790/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0451 - accuracy: 0.9800\n",
            "Epoch 791/1500\n",
            "50/50 [==============================] - 0s 280us/sample - loss: 0.0451 - accuracy: 0.9800\n",
            "Epoch 792/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0450 - accuracy: 0.9800\n",
            "Epoch 793/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0451 - accuracy: 0.9800\n",
            "Epoch 794/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0449 - accuracy: 0.9800\n",
            "Epoch 795/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0448 - accuracy: 0.9800\n",
            "Epoch 796/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0449 - accuracy: 0.9800\n",
            "Epoch 797/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0447 - accuracy: 0.9800\n",
            "Epoch 798/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0447 - accuracy: 0.9800\n",
            "Epoch 799/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0446 - accuracy: 0.9800\n",
            "Epoch 800/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0446 - accuracy: 0.9800\n",
            "Epoch 801/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0446 - accuracy: 0.9800\n",
            "Epoch 802/1500\n",
            "50/50 [==============================] - 0s 423us/sample - loss: 0.0446 - accuracy: 0.9800\n",
            "Epoch 803/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0447 - accuracy: 0.9800\n",
            "Epoch 804/1500\n",
            "50/50 [==============================] - 0s 397us/sample - loss: 0.0445 - accuracy: 0.9800\n",
            "Epoch 805/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0444 - accuracy: 0.9800\n",
            "Epoch 806/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0446 - accuracy: 0.9800\n",
            "Epoch 807/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0443 - accuracy: 0.9800\n",
            "Epoch 808/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0443 - accuracy: 0.9800\n",
            "Epoch 809/1500\n",
            "50/50 [==============================] - 0s 397us/sample - loss: 0.0442 - accuracy: 0.9800\n",
            "Epoch 810/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0444 - accuracy: 0.9600\n",
            "Epoch 811/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0442 - accuracy: 0.9800\n",
            "Epoch 812/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0441 - accuracy: 0.9800\n",
            "Epoch 813/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.0441 - accuracy: 0.9800\n",
            "Epoch 814/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0440 - accuracy: 0.9800\n",
            "Epoch 815/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0441 - accuracy: 0.9800\n",
            "Epoch 816/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0441 - accuracy: 0.9800\n",
            "Epoch 817/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0439 - accuracy: 0.9800\n",
            "Epoch 818/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0438 - accuracy: 0.9800\n",
            "Epoch 819/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0438 - accuracy: 0.9800\n",
            "Epoch 820/1500\n",
            "50/50 [==============================] - 0s 381us/sample - loss: 0.0438 - accuracy: 0.9800\n",
            "Epoch 821/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0438 - accuracy: 0.9800\n",
            "Epoch 822/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0437 - accuracy: 0.9800\n",
            "Epoch 823/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 0.0437 - accuracy: 0.9800\n",
            "Epoch 824/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0436 - accuracy: 0.9800\n",
            "Epoch 825/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0436 - accuracy: 0.9800\n",
            "Epoch 826/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 0.0438 - accuracy: 0.9800\n",
            "Epoch 827/1500\n",
            "50/50 [==============================] - 0s 372us/sample - loss: 0.0435 - accuracy: 0.9800\n",
            "Epoch 828/1500\n",
            "50/50 [==============================] - 0s 373us/sample - loss: 0.0436 - accuracy: 0.9800\n",
            "Epoch 829/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0435 - accuracy: 0.9800\n",
            "Epoch 830/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.0434 - accuracy: 0.9800\n",
            "Epoch 831/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0434 - accuracy: 0.9800\n",
            "Epoch 832/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0434 - accuracy: 0.9800\n",
            "Epoch 833/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.0434 - accuracy: 0.9800\n",
            "Epoch 834/1500\n",
            "50/50 [==============================] - 0s 290us/sample - loss: 0.0435 - accuracy: 0.9800\n",
            "Epoch 835/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0433 - accuracy: 0.9800\n",
            "Epoch 836/1500\n",
            "50/50 [==============================] - 0s 460us/sample - loss: 0.0433 - accuracy: 0.9800\n",
            "Epoch 837/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0433 - accuracy: 0.9800\n",
            "Epoch 838/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0432 - accuracy: 0.9800\n",
            "Epoch 839/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0432 - accuracy: 0.9800\n",
            "Epoch 840/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0432 - accuracy: 0.9800\n",
            "Epoch 841/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0433 - accuracy: 0.9800\n",
            "Epoch 842/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0431 - accuracy: 0.9800\n",
            "Epoch 843/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0432 - accuracy: 0.9800\n",
            "Epoch 844/1500\n",
            "50/50 [==============================] - 0s 378us/sample - loss: 0.0430 - accuracy: 0.9800\n",
            "Epoch 845/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0430 - accuracy: 0.9800\n",
            "Epoch 846/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 847/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 848/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0428 - accuracy: 0.9800\n",
            "Epoch 849/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0428 - accuracy: 0.9800\n",
            "Epoch 850/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0428 - accuracy: 0.9800\n",
            "Epoch 851/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0428 - accuracy: 0.9800\n",
            "Epoch 852/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0428 - accuracy: 0.9800\n",
            "Epoch 853/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 854/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 855/1500\n",
            "50/50 [==============================] - 0s 444us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 856/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0430 - accuracy: 0.9800\n",
            "Epoch 857/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 858/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0430 - accuracy: 0.9800\n",
            "Epoch 859/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 860/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0428 - accuracy: 0.9800\n",
            "Epoch 861/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0427 - accuracy: 0.9800\n",
            "Epoch 862/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0426 - accuracy: 0.9800\n",
            "Epoch 863/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0427 - accuracy: 0.9800\n",
            "Epoch 864/1500\n",
            "50/50 [==============================] - 0s 290us/sample - loss: 0.0425 - accuracy: 0.9800\n",
            "Epoch 865/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0425 - accuracy: 0.9800\n",
            "Epoch 866/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0423 - accuracy: 0.9800\n",
            "Epoch 867/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0423 - accuracy: 0.9800\n",
            "Epoch 868/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0423 - accuracy: 0.9800\n",
            "Epoch 869/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0423 - accuracy: 0.9800\n",
            "Epoch 870/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0421 - accuracy: 0.9800\n",
            "Epoch 871/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0421 - accuracy: 0.9800\n",
            "Epoch 872/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0420 - accuracy: 0.9800\n",
            "Epoch 873/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0421 - accuracy: 0.9800\n",
            "Epoch 874/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0419 - accuracy: 0.9800\n",
            "Epoch 875/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0418 - accuracy: 0.9800\n",
            "Epoch 876/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0418 - accuracy: 0.9800\n",
            "Epoch 877/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0417 - accuracy: 0.9800\n",
            "Epoch 878/1500\n",
            "50/50 [==============================] - 0s 417us/sample - loss: 0.0417 - accuracy: 0.9800\n",
            "Epoch 879/1500\n",
            "50/50 [==============================] - 0s 408us/sample - loss: 0.0417 - accuracy: 0.9800\n",
            "Epoch 880/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0416 - accuracy: 0.9800\n",
            "Epoch 881/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0416 - accuracy: 0.9800\n",
            "Epoch 882/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0416 - accuracy: 0.9800\n",
            "Epoch 883/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0415 - accuracy: 0.9800\n",
            "Epoch 884/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0416 - accuracy: 0.9800\n",
            "Epoch 885/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0416 - accuracy: 0.9800\n",
            "Epoch 886/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0414 - accuracy: 0.9800\n",
            "Epoch 887/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0414 - accuracy: 0.9800\n",
            "Epoch 888/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0414 - accuracy: 0.9800\n",
            "Epoch 889/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0414 - accuracy: 0.9800\n",
            "Epoch 890/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0413 - accuracy: 0.9800\n",
            "Epoch 891/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0413 - accuracy: 0.9800\n",
            "Epoch 892/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0412 - accuracy: 0.9800\n",
            "Epoch 893/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0412 - accuracy: 0.9800\n",
            "Epoch 894/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0412 - accuracy: 0.9800\n",
            "Epoch 895/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0412 - accuracy: 0.9600\n",
            "Epoch 896/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0411 - accuracy: 0.9800\n",
            "Epoch 897/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0411 - accuracy: 0.9800\n",
            "Epoch 898/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0413 - accuracy: 0.9800\n",
            "Epoch 899/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0410 - accuracy: 0.9800\n",
            "Epoch 900/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0410 - accuracy: 0.9800\n",
            "Epoch 901/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0411 - accuracy: 0.9800\n",
            "Epoch 902/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0410 - accuracy: 0.9800\n",
            "Epoch 903/1500\n",
            "50/50 [==============================] - 0s 410us/sample - loss: 0.0409 - accuracy: 0.9800\n",
            "Epoch 904/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0410 - accuracy: 0.9800\n",
            "Epoch 905/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0410 - accuracy: 0.9800\n",
            "Epoch 906/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0410 - accuracy: 0.9800\n",
            "Epoch 907/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0408 - accuracy: 0.9800\n",
            "Epoch 908/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0408 - accuracy: 0.9800\n",
            "Epoch 909/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 910/1500\n",
            "50/50 [==============================] - 0s 444us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 911/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 912/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 913/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 914/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 915/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0408 - accuracy: 0.9800\n",
            "Epoch 916/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 917/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0405 - accuracy: 0.9800\n",
            "Epoch 918/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0405 - accuracy: 0.9800\n",
            "Epoch 919/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0405 - accuracy: 0.9800\n",
            "Epoch 920/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0407 - accuracy: 0.9800\n",
            "Epoch 921/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0404 - accuracy: 0.9800\n",
            "Epoch 922/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0404 - accuracy: 0.9800\n",
            "Epoch 923/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0404 - accuracy: 0.9800\n",
            "Epoch 924/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0403 - accuracy: 0.9800\n",
            "Epoch 925/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0403 - accuracy: 0.9800\n",
            "Epoch 926/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0403 - accuracy: 0.9800\n",
            "Epoch 927/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0402 - accuracy: 0.9800\n",
            "Epoch 928/1500\n",
            "50/50 [==============================] - 0s 280us/sample - loss: 0.0402 - accuracy: 0.9800\n",
            "Epoch 929/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0402 - accuracy: 0.9800\n",
            "Epoch 930/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0404 - accuracy: 0.9800\n",
            "Epoch 931/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0402 - accuracy: 0.9800\n",
            "Epoch 932/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0401 - accuracy: 0.9800\n",
            "Epoch 933/1500\n",
            "50/50 [==============================] - 0s 390us/sample - loss: 0.0401 - accuracy: 0.9800\n",
            "Epoch 934/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0401 - accuracy: 0.9800\n",
            "Epoch 935/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0400 - accuracy: 0.9800\n",
            "Epoch 936/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0399 - accuracy: 0.9800\n",
            "Epoch 937/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0403 - accuracy: 0.9800\n",
            "Epoch 938/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0400 - accuracy: 0.9800\n",
            "Epoch 939/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0399 - accuracy: 0.9800\n",
            "Epoch 940/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0399 - accuracy: 0.9800\n",
            "Epoch 941/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0399 - accuracy: 0.9800\n",
            "Epoch 942/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 943/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0399 - accuracy: 0.9800\n",
            "Epoch 944/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 945/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 946/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 947/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 948/1500\n",
            "50/50 [==============================] - 0s 279us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 949/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 950/1500\n",
            "50/50 [==============================] - 0s 361us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 951/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 952/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 953/1500\n",
            "50/50 [==============================] - 0s 358us/sample - loss: 0.0396 - accuracy: 0.9800\n",
            "Epoch 954/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 955/1500\n",
            "50/50 [==============================] - 0s 290us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 956/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0398 - accuracy: 0.9800\n",
            "Epoch 957/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 958/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0396 - accuracy: 0.9800\n",
            "Epoch 959/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0396 - accuracy: 0.9800\n",
            "Epoch 960/1500\n",
            "50/50 [==============================] - 0s 372us/sample - loss: 0.0397 - accuracy: 0.9800\n",
            "Epoch 961/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0395 - accuracy: 0.9800\n",
            "Epoch 962/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0395 - accuracy: 0.9800\n",
            "Epoch 963/1500\n",
            "50/50 [==============================] - 0s 384us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 964/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 965/1500\n",
            "50/50 [==============================] - 0s 442us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 966/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 967/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 968/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0393 - accuracy: 0.9800\n",
            "Epoch 969/1500\n",
            "50/50 [==============================] - 0s 363us/sample - loss: 0.0395 - accuracy: 0.9800\n",
            "Epoch 970/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 971/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0394 - accuracy: 0.9800\n",
            "Epoch 972/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0392 - accuracy: 0.9800\n",
            "Epoch 973/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0392 - accuracy: 0.9800\n",
            "Epoch 974/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0392 - accuracy: 0.9800\n",
            "Epoch 975/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0391 - accuracy: 0.9800\n",
            "Epoch 976/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0390 - accuracy: 0.9800\n",
            "Epoch 977/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 978/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0388 - accuracy: 0.9800\n",
            "Epoch 979/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 980/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 981/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0388 - accuracy: 0.9800\n",
            "Epoch 982/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 983/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 984/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 985/1500\n",
            "50/50 [==============================] - 0s 381us/sample - loss: 0.0391 - accuracy: 0.9800\n",
            "Epoch 986/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0390 - accuracy: 0.9800\n",
            "Epoch 987/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 988/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0388 - accuracy: 0.9800\n",
            "Epoch 989/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.0390 - accuracy: 0.9800\n",
            "Epoch 990/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 991/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 992/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 0.0387 - accuracy: 0.9800\n",
            "Epoch 993/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.0387 - accuracy: 0.9800\n",
            "Epoch 994/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0388 - accuracy: 0.9800\n",
            "Epoch 995/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0386 - accuracy: 0.9800\n",
            "Epoch 996/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0387 - accuracy: 0.9800\n",
            "Epoch 997/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.0385 - accuracy: 0.9800\n",
            "Epoch 998/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0385 - accuracy: 0.9800\n",
            "Epoch 999/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0386 - accuracy: 0.9800\n",
            "Epoch 1000/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0385 - accuracy: 0.9800\n",
            "Epoch 1001/1500\n",
            "50/50 [==============================] - 0s 373us/sample - loss: 0.0386 - accuracy: 0.9800\n",
            "Epoch 1002/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0384 - accuracy: 0.9800\n",
            "Epoch 1003/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0384 - accuracy: 0.9800\n",
            "Epoch 1004/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0385 - accuracy: 0.9800\n",
            "Epoch 1005/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0385 - accuracy: 0.9800\n",
            "Epoch 1006/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0383 - accuracy: 0.9800\n",
            "Epoch 1007/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0384 - accuracy: 0.9800\n",
            "Epoch 1008/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0383 - accuracy: 0.9800\n",
            "Epoch 1009/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0383 - accuracy: 0.9800\n",
            "Epoch 1010/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1011/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0383 - accuracy: 0.9800\n",
            "Epoch 1012/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1013/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1014/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1015/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1016/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0383 - accuracy: 0.9800\n",
            "Epoch 1017/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1018/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0381 - accuracy: 0.9800\n",
            "Epoch 1019/1500\n",
            "50/50 [==============================] - 0s 410us/sample - loss: 0.0381 - accuracy: 0.9800\n",
            "Epoch 1020/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0381 - accuracy: 0.9800\n",
            "Epoch 1021/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0382 - accuracy: 0.9800\n",
            "Epoch 1022/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0381 - accuracy: 0.9800\n",
            "Epoch 1023/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0380 - accuracy: 0.9800\n",
            "Epoch 1024/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0380 - accuracy: 0.9800\n",
            "Epoch 1025/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0379 - accuracy: 0.9800\n",
            "Epoch 1026/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0379 - accuracy: 0.9800\n",
            "Epoch 1027/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1028/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1029/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1030/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1031/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1032/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1033/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1034/1500\n",
            "50/50 [==============================] - 0s 376us/sample - loss: 0.0379 - accuracy: 0.9800\n",
            "Epoch 1035/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1036/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0380 - accuracy: 0.9800\n",
            "Epoch 1037/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1038/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0378 - accuracy: 0.9800\n",
            "Epoch 1039/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0377 - accuracy: 0.9800\n",
            "Epoch 1040/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0376 - accuracy: 0.9800\n",
            "Epoch 1041/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0376 - accuracy: 0.9800\n",
            "Epoch 1042/1500\n",
            "50/50 [==============================] - 0s 397us/sample - loss: 0.0376 - accuracy: 0.9800\n",
            "Epoch 1043/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0376 - accuracy: 0.9800\n",
            "Epoch 1044/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0375 - accuracy: 0.9800\n",
            "Epoch 1045/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1046/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0375 - accuracy: 0.9800\n",
            "Epoch 1047/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0377 - accuracy: 0.9800\n",
            "Epoch 1048/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0375 - accuracy: 0.9800\n",
            "Epoch 1049/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1050/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0376 - accuracy: 0.9800\n",
            "Epoch 1051/1500\n",
            "50/50 [==============================] - 0s 264us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1052/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1053/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1054/1500\n",
            "50/50 [==============================] - 0s 392us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1055/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0373 - accuracy: 0.9800\n",
            "Epoch 1056/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1057/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0373 - accuracy: 0.9800\n",
            "Epoch 1058/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.0373 - accuracy: 0.9800\n",
            "Epoch 1059/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0374 - accuracy: 0.9800\n",
            "Epoch 1060/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1061/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1062/1500\n",
            "50/50 [==============================] - 0s 274us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1063/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1064/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1065/1500\n",
            "50/50 [==============================] - 0s 379us/sample - loss: 0.0371 - accuracy: 0.9800\n",
            "Epoch 1066/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0372 - accuracy: 0.9600\n",
            "Epoch 1067/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0371 - accuracy: 0.9800\n",
            "Epoch 1068/1500\n",
            "50/50 [==============================] - 0s 416us/sample - loss: 0.0371 - accuracy: 0.9800\n",
            "Epoch 1069/1500\n",
            "50/50 [==============================] - 0s 284us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1070/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0370 - accuracy: 0.9800\n",
            "Epoch 1071/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0371 - accuracy: 0.9800\n",
            "Epoch 1072/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0370 - accuracy: 0.9800\n",
            "Epoch 1073/1500\n",
            "50/50 [==============================] - 0s 438us/sample - loss: 0.0370 - accuracy: 0.9800\n",
            "Epoch 1074/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0372 - accuracy: 0.9800\n",
            "Epoch 1075/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0370 - accuracy: 0.9800\n",
            "Epoch 1076/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0371 - accuracy: 0.9800\n",
            "Epoch 1077/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0370 - accuracy: 0.9800\n",
            "Epoch 1078/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0369 - accuracy: 0.9800\n",
            "Epoch 1079/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0369 - accuracy: 0.9800\n",
            "Epoch 1080/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1081/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1082/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1083/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1084/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.0371 - accuracy: 0.9800\n",
            "Epoch 1085/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0370 - accuracy: 0.9800\n",
            "Epoch 1086/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1087/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1088/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1089/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1090/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1091/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0367 - accuracy: 0.9800\n",
            "Epoch 1092/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0367 - accuracy: 0.9800\n",
            "Epoch 1093/1500\n",
            "50/50 [==============================] - 0s 281us/sample - loss: 0.0368 - accuracy: 0.9800\n",
            "Epoch 1094/1500\n",
            "50/50 [==============================] - 0s 364us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1095/1500\n",
            "50/50 [==============================] - 0s 396us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1096/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1097/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1098/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1099/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1100/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1101/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1102/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1103/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1104/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1105/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1106/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1107/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0366 - accuracy: 0.9800\n",
            "Epoch 1108/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1109/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1110/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1111/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1112/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1113/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1114/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1115/1500\n",
            "50/50 [==============================] - 0s 366us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1116/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1117/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1118/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0365 - accuracy: 0.9800\n",
            "Epoch 1119/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 1120/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 1121/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 1122/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 1123/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1124/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1125/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1126/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0361 - accuracy: 0.9800\n",
            "Epoch 1127/1500\n",
            "50/50 [==============================] - 0s 392us/sample - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 1128/1500\n",
            "50/50 [==============================] - 0s 439us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1129/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 1130/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1131/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1132/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0360 - accuracy: 0.9800\n",
            "Epoch 1133/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0361 - accuracy: 0.9800\n",
            "Epoch 1134/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0362 - accuracy: 0.9800\n",
            "Epoch 1135/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0360 - accuracy: 0.9800\n",
            "Epoch 1136/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0360 - accuracy: 0.9800\n",
            "Epoch 1137/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1138/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1139/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1140/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1141/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0360 - accuracy: 0.9800\n",
            "Epoch 1142/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1143/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1144/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1145/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1146/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0360 - accuracy: 0.9800\n",
            "Epoch 1147/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1148/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1149/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1150/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1151/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1152/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1153/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1154/1500\n",
            "50/50 [==============================] - 0s 281us/sample - loss: 0.0360 - accuracy: 0.9800\n",
            "Epoch 1155/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1156/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 1157/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0357 - accuracy: 0.9800\n",
            "Epoch 1158/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0359 - accuracy: 0.9800\n",
            "Epoch 1159/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0357 - accuracy: 0.9800\n",
            "Epoch 1160/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0356 - accuracy: 0.9800\n",
            "Epoch 1161/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0356 - accuracy: 0.9800\n",
            "Epoch 1162/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0357 - accuracy: 0.9800\n",
            "Epoch 1163/1500\n",
            "50/50 [==============================] - 0s 381us/sample - loss: 0.0356 - accuracy: 0.9800\n",
            "Epoch 1164/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1165/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1166/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0356 - accuracy: 0.9600\n",
            "Epoch 1167/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0356 - accuracy: 0.9800\n",
            "Epoch 1168/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0356 - accuracy: 0.9800\n",
            "Epoch 1169/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1170/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1171/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1172/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1173/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1174/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1175/1500\n",
            "50/50 [==============================] - 0s 266us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1176/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 1177/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1178/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1179/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1180/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1181/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0354 - accuracy: 0.9800\n",
            "Epoch 1182/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1183/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0354 - accuracy: 0.9600\n",
            "Epoch 1184/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1185/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1186/1500\n",
            "50/50 [==============================] - 0s 273us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1187/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1188/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1189/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1190/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1191/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1192/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1193/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1194/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1195/1500\n",
            "50/50 [==============================] - 0s 371us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1196/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0353 - accuracy: 0.9800\n",
            "Epoch 1197/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1198/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1199/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1200/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1201/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1202/1500\n",
            "50/50 [==============================] - 0s 358us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1203/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1204/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1205/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1206/1500\n",
            "50/50 [==============================] - 0s 383us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1207/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1208/1500\n",
            "50/50 [==============================] - 0s 373us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1209/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1210/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1211/1500\n",
            "50/50 [==============================] - 0s 291us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1212/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1213/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1214/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0349 - accuracy: 0.9800\n",
            "Epoch 1215/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0349 - accuracy: 0.9800\n",
            "Epoch 1216/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1217/1500\n",
            "50/50 [==============================] - 0s 360us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1218/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1219/1500\n",
            "50/50 [==============================] - 0s 388us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1220/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0351 - accuracy: 0.9800\n",
            "Epoch 1221/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1222/1500\n",
            "50/50 [==============================] - 0s 281us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1223/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1224/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1225/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1226/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1227/1500\n",
            "50/50 [==============================] - 0s 363us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1228/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 1229/1500\n",
            "50/50 [==============================] - 0s 371us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1230/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1231/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1232/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0350 - accuracy: 0.9800\n",
            "Epoch 1233/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.0349 - accuracy: 0.9800\n",
            "Epoch 1234/1500\n",
            "50/50 [==============================] - 0s 380us/sample - loss: 0.0348 - accuracy: 0.9800\n",
            "Epoch 1235/1500\n",
            "50/50 [==============================] - 0s 372us/sample - loss: 0.0347 - accuracy: 0.9800\n",
            "Epoch 1236/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0349 - accuracy: 0.9800\n",
            "Epoch 1237/1500\n",
            "50/50 [==============================] - 0s 375us/sample - loss: 0.0347 - accuracy: 0.9800\n",
            "Epoch 1238/1500\n",
            "50/50 [==============================] - 0s 384us/sample - loss: 0.0346 - accuracy: 0.9800\n",
            "Epoch 1239/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0346 - accuracy: 0.9800\n",
            "Epoch 1240/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0346 - accuracy: 0.9800\n",
            "Epoch 1241/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0346 - accuracy: 0.9800\n",
            "Epoch 1242/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1243/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1244/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1245/1500\n",
            "50/50 [==============================] - 0s 267us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1246/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1247/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1248/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1249/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1250/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1251/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1252/1500\n",
            "50/50 [==============================] - 0s 406us/sample - loss: 0.0347 - accuracy: 0.9800\n",
            "Epoch 1253/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1254/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0346 - accuracy: 0.9800\n",
            "Epoch 1255/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1256/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1257/1500\n",
            "50/50 [==============================] - 0s 301us/sample - loss: 0.0346 - accuracy: 0.9800\n",
            "Epoch 1258/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1259/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1260/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0344 - accuracy: 0.9800\n",
            "Epoch 1261/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0344 - accuracy: 0.9800\n",
            "Epoch 1262/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0343 - accuracy: 0.9800\n",
            "Epoch 1263/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 1264/1500\n",
            "50/50 [==============================] - 0s 271us/sample - loss: 0.0344 - accuracy: 0.9800\n",
            "Epoch 1265/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0343 - accuracy: 0.9800\n",
            "Epoch 1266/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1267/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1268/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0345 - accuracy: 0.9600\n",
            "Epoch 1269/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1270/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0343 - accuracy: 0.9800\n",
            "Epoch 1271/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1272/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1273/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0343 - accuracy: 0.9600\n",
            "Epoch 1274/1500\n",
            "50/50 [==============================] - 0s 379us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1275/1500\n",
            "50/50 [==============================] - 0s 396us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1276/1500\n",
            "50/50 [==============================] - 0s 289us/sample - loss: 0.0342 - accuracy: 0.9600\n",
            "Epoch 1277/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1278/1500\n",
            "50/50 [==============================] - 0s 284us/sample - loss: 0.0343 - accuracy: 0.9800\n",
            "Epoch 1279/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1280/1500\n",
            "50/50 [==============================] - 0s 356us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1281/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1282/1500\n",
            "50/50 [==============================] - 0s 340us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1283/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0342 - accuracy: 0.9800\n",
            "Epoch 1284/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1285/1500\n",
            "50/50 [==============================] - 0s 459us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1286/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0341 - accuracy: 0.9600\n",
            "Epoch 1287/1500\n",
            "50/50 [==============================] - 0s 382us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1288/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1289/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1290/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1291/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1292/1500\n",
            "50/50 [==============================] - 0s 411us/sample - loss: 0.0341 - accuracy: 0.9800\n",
            "Epoch 1293/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1294/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1295/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1296/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1297/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1298/1500\n",
            "50/50 [==============================] - 0s 382us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1299/1500\n",
            "50/50 [==============================] - 0s 395us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1300/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1301/1500\n",
            "50/50 [==============================] - 0s 327us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1302/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1303/1500\n",
            "50/50 [==============================] - 0s 310us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1304/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1305/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0340 - accuracy: 0.9800\n",
            "Epoch 1306/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1307/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1308/1500\n",
            "50/50 [==============================] - 0s 323us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1309/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1310/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1311/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1312/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1313/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1314/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0339 - accuracy: 0.9800\n",
            "Epoch 1315/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1316/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1317/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1318/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1319/1500\n",
            "50/50 [==============================] - 0s 358us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1320/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1321/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1322/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1323/1500\n",
            "50/50 [==============================] - 0s 324us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1324/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1325/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1326/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0338 - accuracy: 0.9800\n",
            "Epoch 1327/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1328/1500\n",
            "50/50 [==============================] - 0s 420us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1329/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1330/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1331/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1332/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1333/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1334/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1335/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1336/1500\n",
            "50/50 [==============================] - 0s 343us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1337/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1338/1500\n",
            "50/50 [==============================] - 0s 369us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1339/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1340/1500\n",
            "50/50 [==============================] - 0s 406us/sample - loss: 0.0337 - accuracy: 0.9600\n",
            "Epoch 1341/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1342/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0336 - accuracy: 0.9800\n",
            "Epoch 1343/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1344/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0337 - accuracy: 0.9800\n",
            "Epoch 1345/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1346/1500\n",
            "50/50 [==============================] - 0s 409us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1347/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1348/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1349/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1350/1500\n",
            "50/50 [==============================] - 0s 304us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1351/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1352/1500\n",
            "50/50 [==============================] - 0s 333us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1353/1500\n",
            "50/50 [==============================] - 0s 305us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1354/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1355/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1356/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1357/1500\n",
            "50/50 [==============================] - 0s 368us/sample - loss: 0.0334 - accuracy: 0.9600\n",
            "Epoch 1358/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 1359/1500\n",
            "50/50 [==============================] - 0s 338us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1360/1500\n",
            "50/50 [==============================] - 0s 359us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1361/1500\n",
            "50/50 [==============================] - 0s 335us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1362/1500\n",
            "50/50 [==============================] - 0s 317us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1363/1500\n",
            "50/50 [==============================] - 0s 319us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1364/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1365/1500\n",
            "50/50 [==============================] - 0s 382us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1366/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1367/1500\n",
            "50/50 [==============================] - 0s 330us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1368/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0334 - accuracy: 0.9800\n",
            "Epoch 1369/1500\n",
            "50/50 [==============================] - 0s 336us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1370/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1371/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1372/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1373/1500\n",
            "50/50 [==============================] - 0s 365us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1374/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1375/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1376/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1377/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1378/1500\n",
            "50/50 [==============================] - 0s 353us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1379/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1380/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1381/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0333 - accuracy: 0.9800\n",
            "Epoch 1382/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1383/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1384/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1385/1500\n",
            "50/50 [==============================] - 0s 262us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1386/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1387/1500\n",
            "50/50 [==============================] - 0s 406us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1388/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1389/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1390/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1391/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1392/1500\n",
            "50/50 [==============================] - 0s 349us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1393/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1394/1500\n",
            "50/50 [==============================] - 0s 355us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1395/1500\n",
            "50/50 [==============================] - 0s 362us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1396/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1397/1500\n",
            "50/50 [==============================] - 0s 307us/sample - loss: 0.0332 - accuracy: 0.9800\n",
            "Epoch 1398/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1399/1500\n",
            "50/50 [==============================] - 0s 424us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1400/1500\n",
            "50/50 [==============================] - 0s 352us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1401/1500\n",
            "50/50 [==============================] - 0s 339us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1402/1500\n",
            "50/50 [==============================] - 0s 377us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1403/1500\n",
            "50/50 [==============================] - 0s 370us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1404/1500\n",
            "50/50 [==============================] - 0s 342us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1405/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1406/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1407/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1408/1500\n",
            "50/50 [==============================] - 0s 334us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1409/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1410/1500\n",
            "50/50 [==============================] - 0s 277us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1411/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1412/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1413/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1414/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1415/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 1416/1500\n",
            "50/50 [==============================] - 0s 344us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1417/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1418/1500\n",
            "50/50 [==============================] - 0s 302us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1419/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0330 - accuracy: 0.9800\n",
            "Epoch 1420/1500\n",
            "50/50 [==============================] - 0s 358us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1421/1500\n",
            "50/50 [==============================] - 0s 374us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1422/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1423/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1424/1500\n",
            "50/50 [==============================] - 0s 314us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1425/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1426/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1427/1500\n",
            "50/50 [==============================] - 0s 281us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1428/1500\n",
            "50/50 [==============================] - 0s 346us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1429/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1430/1500\n",
            "50/50 [==============================] - 0s 331us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1431/1500\n",
            "50/50 [==============================] - 0s 290us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1432/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1433/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1434/1500\n",
            "50/50 [==============================] - 0s 332us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1435/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1436/1500\n",
            "50/50 [==============================] - 0s 367us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1437/1500\n",
            "50/50 [==============================] - 0s 345us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1438/1500\n",
            "50/50 [==============================] - 0s 382us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1439/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1440/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1441/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1442/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1443/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1444/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1445/1500\n",
            "50/50 [==============================] - 0s 283us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1446/1500\n",
            "50/50 [==============================] - 0s 295us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1447/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1448/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1449/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1450/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1451/1500\n",
            "50/50 [==============================] - 0s 312us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1452/1500\n",
            "50/50 [==============================] - 0s 313us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1453/1500\n",
            "50/50 [==============================] - 0s 293us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1454/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1455/1500\n",
            "50/50 [==============================] - 0s 269us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1456/1500\n",
            "50/50 [==============================] - 0s 303us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1457/1500\n",
            "50/50 [==============================] - 0s 361us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1458/1500\n",
            "50/50 [==============================] - 0s 321us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1459/1500\n",
            "50/50 [==============================] - 0s 326us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1460/1500\n",
            "50/50 [==============================] - 0s 298us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1461/1500\n",
            "50/50 [==============================] - 0s 289us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1462/1500\n",
            "50/50 [==============================] - 0s 292us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1463/1500\n",
            "50/50 [==============================] - 0s 357us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1464/1500\n",
            "50/50 [==============================] - 0s 297us/sample - loss: 0.0326 - accuracy: 0.9800\n",
            "Epoch 1465/1500\n",
            "50/50 [==============================] - 0s 308us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1466/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1467/1500\n",
            "50/50 [==============================] - 0s 347us/sample - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 1468/1500\n",
            "50/50 [==============================] - 0s 328us/sample - loss: 0.0328 - accuracy: 0.9800\n",
            "Epoch 1469/1500\n",
            "50/50 [==============================] - 0s 337us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1470/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0327 - accuracy: 0.9800\n",
            "Epoch 1471/1500\n",
            "50/50 [==============================] - 0s 296us/sample - loss: 0.0325 - accuracy: 0.9800\n",
            "Epoch 1472/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0325 - accuracy: 0.9800\n",
            "Epoch 1473/1500\n",
            "50/50 [==============================] - 0s 287us/sample - loss: 0.0325 - accuracy: 0.9800\n",
            "Epoch 1474/1500\n",
            "50/50 [==============================] - 0s 299us/sample - loss: 0.0325 - accuracy: 0.9800\n",
            "Epoch 1475/1500\n",
            "50/50 [==============================] - 0s 320us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1476/1500\n",
            "50/50 [==============================] - 0s 309us/sample - loss: 0.0326 - accuracy: 0.9600\n",
            "Epoch 1477/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0325 - accuracy: 0.9800\n",
            "Epoch 1478/1500\n",
            "50/50 [==============================] - 0s 350us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1479/1500\n",
            "50/50 [==============================] - 0s 329us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1480/1500\n",
            "50/50 [==============================] - 0s 351us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1481/1500\n",
            "50/50 [==============================] - 0s 341us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1482/1500\n",
            "50/50 [==============================] - 0s 318us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1483/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1484/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1485/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1486/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1487/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0325 - accuracy: 0.9800\n",
            "Epoch 1488/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1489/1500\n",
            "50/50 [==============================] - 0s 316us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1490/1500\n",
            "50/50 [==============================] - 0s 311us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1491/1500\n",
            "50/50 [==============================] - 0s 315us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1492/1500\n",
            "50/50 [==============================] - 0s 322us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1493/1500\n",
            "50/50 [==============================] - 0s 300us/sample - loss: 0.0324 - accuracy: 0.9600\n",
            "Epoch 1494/1500\n",
            "50/50 [==============================] - 0s 286us/sample - loss: 0.0323 - accuracy: 0.9600\n",
            "Epoch 1495/1500\n",
            "50/50 [==============================] - 0s 348us/sample - loss: 0.0324 - accuracy: 0.9800\n",
            "Epoch 1496/1500\n",
            "50/50 [==============================] - 0s 306us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1497/1500\n",
            "50/50 [==============================] - 0s 325us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1498/1500\n",
            "50/50 [==============================] - 0s 294us/sample - loss: 0.0322 - accuracy: 0.9800\n",
            "Epoch 1499/1500\n",
            "50/50 [==============================] - 0s 279us/sample - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 1500/1500\n",
            "50/50 [==============================] - 0s 354us/sample - loss: 0.0322 - accuracy: 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCOmshu-b_Mi",
        "colab_type": "code",
        "outputId": "3597a969-3e0f-4b9c-987b-d3d789ccd0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  # plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  # plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qqzKZiOkie7",
        "colab_type": "text"
      },
      "source": [
        "Most Important ..lets now test it :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr2g8uc0kl91",
        "colab_type": "code",
        "outputId": "b93bfa8f-83b0-462c-ff79-262034bcb993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "seed_text  = 'My name is Ravi and I am an'\n",
        "next_words = 5\n",
        "#tokenizer = Tokenizer()\n",
        "\n",
        "for _ in range(next_words):\n",
        "  sequence = tokenizer.texts_to_sequences([seed_text])\n",
        "  sequence = sequence[0]\n",
        "  # print(sequence)\n",
        "  padded_sequence =  pad_sequences([sequence] , maxlen = max_length -1, padding = 'pre')\n",
        "  # print(padded_sequence)\n",
        "  # print(type(padded_sequence))\n",
        "  pred = model.predict_classes(padded_sequence)\n",
        "  # print(x)\n",
        "  pred_word = \"\"\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pred:\n",
        "      pred_word = word\n",
        "      #print('Predicted Word : ',word)\n",
        "      break\n",
        "  seed_text = seed_text + \" \" + pred_word\n",
        "  print(seed_text)\n",
        "print('\\n',seed_text)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My name is Ravi and I am an thy\n",
            "My name is Ravi and I am an thy thy\n",
            "My name is Ravi and I am an thy thy lightst\n",
            "My name is Ravi and I am an thy thy lightst flame\n",
            "My name is Ravi and I am an thy thy lightst flame with\n",
            "\n",
            " My name is Ravi and I am an thy thy lightst flame with\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6wKxbfa1IMr",
        "colab_type": "text"
      },
      "source": [
        "### Exercise Week 4 Shakespeare Questions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8Ut4F15tYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYHAcT45zFf",
        "colab_type": "code",
        "outputId": "38297084-7469-4b31-a8d5-970bf3885276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_oMEcsM5-ZS",
        "colab_type": "code",
        "outputId": "0d671bd8-cabe-4939-8e9c-345ae67d2b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "#-----------------Download the Data and Create the Corpus-----------------\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(type(corpus))\n",
        "print(len(corpus))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 08:18:19--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-04-15 08:18:19 (128 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n",
            "<class 'list'>\n",
            "2159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6DGqOs1Mon",
        "colab_type": "code",
        "outputId": "ebabe286-6973-4042-fd93-f7e818b41ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gczyFPxe1M1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = tf.keras.utils.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL1886aq1M4w",
        "colab_type": "code",
        "outputId": "b437fe68-8018-4a56-a327-0373ddf21dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "Embedding_dim = 32\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding( total_words , Embedding_dim , input_length = (max_sequence_len-1) )) # Your Embedding Layer)\n",
        "\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True)))# An LSTM Layer)\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2)) # A dropout layer)\n",
        "\n",
        "model.add(tf.keras.layers.LSTM(32)) # Another LSTM Layer)\n",
        "\n",
        "model.add(tf.keras.layers.Dense(total_words/2 , \n",
        "                                activation = 'relu' , \n",
        "                                kernel_regularizer = tf.keras.regularizers.l2(0.01))) # A Dense Layer including regularizers)\n",
        "\n",
        "model.add(tf.keras.layers.Dense(total_words , activation = 'softmax'))# A Dense Layer)\n",
        "\n",
        "# Pick an optimizer\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'] )   \n",
        "\n",
        "  # Pick a loss function and an optimizer)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7fd6cd9cfb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fd6cd9cfb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7fd6cd9cfb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fd6cd9cfb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fd6cd9cfbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fd6cd9cfbf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7fd6cd9cfbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fd6cd9cfbf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7fd6cd9cfb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fd6cd9cfb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7fd6cd9cfb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fd6cd9cfb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fd6cd9cfbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fd6cd9cfbf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7fd6cd9cfbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fd6cd9cfbf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7fd6cd9cfb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fd6cd9cfb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7fd6cd9cfb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fd6cd9cfb70>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fd6cd9cfbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fd6cd9cfbf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7fd6cd9cfbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fd6cd9cfbf8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 10, 32)            102752    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 10, 64)            16640     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1605)              52965     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 5,341,639\n",
            "Trainable params: 5,341,639\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZjYIJb1M8n",
        "colab_type": "code",
        "outputId": "abb633cf-4202-4f45-82ac-134206851064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 15462 samples\n",
            "Epoch 1/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 6.9048 - accuracy: 0.0224\n",
            "Epoch 2/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.5226 - accuracy: 0.0242\n",
            "Epoch 3/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.4279 - accuracy: 0.0247\n",
            "Epoch 4/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.3210 - accuracy: 0.0277\n",
            "Epoch 5/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.2335 - accuracy: 0.0283\n",
            "Epoch 6/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.1646 - accuracy: 0.0285\n",
            "Epoch 7/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.1082 - accuracy: 0.0318\n",
            "Epoch 8/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.0596 - accuracy: 0.0341\n",
            "Epoch 9/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.0076 - accuracy: 0.0361\n",
            "Epoch 10/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.9587 - accuracy: 0.0370\n",
            "Epoch 11/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.9149 - accuracy: 0.0382\n",
            "Epoch 12/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.8627 - accuracy: 0.0415\n",
            "Epoch 13/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.8105 - accuracy: 0.0411\n",
            "Epoch 14/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.7577 - accuracy: 0.0444\n",
            "Epoch 15/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.7040 - accuracy: 0.0489\n",
            "Epoch 16/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.6483 - accuracy: 0.0503\n",
            "Epoch 17/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.5930 - accuracy: 0.0541\n",
            "Epoch 18/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.5437 - accuracy: 0.0564\n",
            "Epoch 19/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.4867 - accuracy: 0.0605\n",
            "Epoch 20/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.4283 - accuracy: 0.0618\n",
            "Epoch 21/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.3703 - accuracy: 0.0652\n",
            "Epoch 22/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.3141 - accuracy: 0.0686\n",
            "Epoch 23/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.2603 - accuracy: 0.0698\n",
            "Epoch 24/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.2059 - accuracy: 0.0739\n",
            "Epoch 25/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.1493 - accuracy: 0.0776\n",
            "Epoch 26/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.0909 - accuracy: 0.0803\n",
            "Epoch 27/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.0372 - accuracy: 0.0820\n",
            "Epoch 28/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.9834 - accuracy: 0.0898\n",
            "Epoch 29/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.9275 - accuracy: 0.0889\n",
            "Epoch 30/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.8738 - accuracy: 0.0927\n",
            "Epoch 31/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.8128 - accuracy: 0.0957\n",
            "Epoch 32/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.7672 - accuracy: 0.1011\n",
            "Epoch 33/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.7238 - accuracy: 0.1015\n",
            "Epoch 34/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.6693 - accuracy: 0.1054\n",
            "Epoch 35/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.6163 - accuracy: 0.1103\n",
            "Epoch 36/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.5739 - accuracy: 0.1107\n",
            "Epoch 37/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.5211 - accuracy: 0.1174\n",
            "Epoch 38/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.4822 - accuracy: 0.1197\n",
            "Epoch 39/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.4417 - accuracy: 0.1235\n",
            "Epoch 40/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.3943 - accuracy: 0.1252\n",
            "Epoch 41/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.3600 - accuracy: 0.1310\n",
            "Epoch 42/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.3136 - accuracy: 0.1348\n",
            "Epoch 43/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.2754 - accuracy: 0.1414\n",
            "Epoch 44/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.2442 - accuracy: 0.1432\n",
            "Epoch 45/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.2107 - accuracy: 0.1510\n",
            "Epoch 46/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.1684 - accuracy: 0.1497\n",
            "Epoch 47/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.1351 - accuracy: 0.1535\n",
            "Epoch 48/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.0956 - accuracy: 0.1641\n",
            "Epoch 49/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.0755 - accuracy: 0.1641\n",
            "Epoch 50/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.0320 - accuracy: 0.1698\n",
            "Epoch 51/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.9929 - accuracy: 0.1756\n",
            "Epoch 52/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.9829 - accuracy: 0.1810\n",
            "Epoch 53/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.9434 - accuracy: 0.1849\n",
            "Epoch 54/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.9077 - accuracy: 0.1913\n",
            "Epoch 55/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.8757 - accuracy: 0.1926\n",
            "Epoch 56/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.8553 - accuracy: 0.1980\n",
            "Epoch 57/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.8329 - accuracy: 0.2018\n",
            "Epoch 58/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.8030 - accuracy: 0.2057\n",
            "Epoch 59/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.7742 - accuracy: 0.2139\n",
            "Epoch 60/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.7424 - accuracy: 0.2141\n",
            "Epoch 61/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.7212 - accuracy: 0.2198\n",
            "Epoch 62/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.6961 - accuracy: 0.2239\n",
            "Epoch 63/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.6689 - accuracy: 0.2292\n",
            "Epoch 64/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.6422 - accuracy: 0.2355\n",
            "Epoch 65/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.6184 - accuracy: 0.2359\n",
            "Epoch 66/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5889 - accuracy: 0.2397\n",
            "Epoch 67/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5721 - accuracy: 0.2488\n",
            "Epoch 68/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5649 - accuracy: 0.2494\n",
            "Epoch 69/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5280 - accuracy: 0.2535\n",
            "Epoch 70/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5043 - accuracy: 0.2598\n",
            "Epoch 71/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.4787 - accuracy: 0.2614\n",
            "Epoch 72/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.4519 - accuracy: 0.2691\n",
            "Epoch 73/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.4195 - accuracy: 0.2751\n",
            "Epoch 74/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.4171 - accuracy: 0.2733\n",
            "Epoch 75/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.4254 - accuracy: 0.2770\n",
            "Epoch 76/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.3884 - accuracy: 0.2835\n",
            "Epoch 77/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.3352 - accuracy: 0.2894\n",
            "Epoch 78/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.3213 - accuracy: 0.2956\n",
            "Epoch 79/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2981 - accuracy: 0.3000\n",
            "Epoch 80/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2846 - accuracy: 0.3013\n",
            "Epoch 81/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2496 - accuracy: 0.3125\n",
            "Epoch 82/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2453 - accuracy: 0.3142\n",
            "Epoch 83/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2254 - accuracy: 0.3194\n",
            "Epoch 84/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2052 - accuracy: 0.3205\n",
            "Epoch 85/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1845 - accuracy: 0.3246\n",
            "Epoch 86/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1705 - accuracy: 0.3283\n",
            "Epoch 87/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1387 - accuracy: 0.3351\n",
            "Epoch 88/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1272 - accuracy: 0.3374\n",
            "Epoch 89/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1139 - accuracy: 0.3406\n",
            "Epoch 90/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.0871 - accuracy: 0.3485\n",
            "Epoch 91/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.0694 - accuracy: 0.3518\n",
            "Epoch 92/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0543 - accuracy: 0.3538\n",
            "Epoch 93/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0341 - accuracy: 0.3571\n",
            "Epoch 94/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0210 - accuracy: 0.3580\n",
            "Epoch 95/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0101 - accuracy: 0.3628\n",
            "Epoch 96/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9947 - accuracy: 0.3610\n",
            "Epoch 97/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9709 - accuracy: 0.3708\n",
            "Epoch 98/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9478 - accuracy: 0.3755\n",
            "Epoch 99/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9318 - accuracy: 0.3826\n",
            "Epoch 100/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.9105 - accuracy: 0.3829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiNGloq2Bfp-",
        "colab_type": "code",
        "outputId": "24fa6f03-9928-4574-8422-a3dd6953fa38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mxz06KtBf07",
        "colab_type": "code",
        "outputId": "b040a867-7fec-4468-cfb2-49f6fec66a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope that be lay with me ' may shine not am blind ill wide thief a trophies of thy precious shame are near engraft thee still still alone alone dearer memory up gracious told so gone so her thing my thoughts his fiery discontent subjects dead translate past brain kings kings staineth staineth staineth staineth staineth greater dyed decay dyed greater afloat crime greater decay new pride survey night doth mother greater afloat bow kings kings cherish ruining ruining well commits gems light made new ill rehearse wantonness give away young so lie in thee without doth is doth spent truth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMso6lYaHe77",
        "colab_type": "text"
      },
      "source": [
        "###generation @Char level:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KDjlybAQJHc",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/tutorials/text/text_generation \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvYtQVjXu3Ds",
        "colab_type": "text"
      },
      "source": [
        "Text generation with an RNN for Shakespear Dataset @ Char Level :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsZ5uATPvJt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggy18H_vHhZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPAAi6_HvEY9",
        "colab_type": "code",
        "outputId": "2a8766e8-6be6-45c0-af79-4916309cfa36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFBHSr7evREe",
        "colab_type": "text"
      },
      "source": [
        "####Download the Shakespeare Dataset :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7JY_7_-vGNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('Shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4JUQz9uvwqA",
        "colab_type": "text"
      },
      "source": [
        "####Read the Data :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqV6Uv0RvfoE",
        "colab_type": "code",
        "outputId": "afdc1cba-a725-48ca-8bca-426ac974487e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "text = open(path_to_file,'rb').read().decode(encoding = 'utf-8')\n",
        "print(\"Length of the text is : \" , len(text))\n",
        "text[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the text is :  1115394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2lD4dMXwOp-",
        "colab_type": "text"
      },
      "source": [
        "The unique characters in the file :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU9KSJ1QwBx-",
        "colab_type": "code",
        "outputId": "f54b6022-d1cd-4c49-9fda-4ef2b91a2b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print('The number of unique charactes in the vocabulary is : ',len(vocab))\n",
        "print('\\n Some of the chars are :',vocab[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique charactes in the vocabulary is :  65\n",
            "\n",
            " Some of the chars are : ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfBh2Rzewsp8",
        "colab_type": "text"
      },
      "source": [
        "####Process The Text :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft3IwM21wC7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "\n",
        "char2id = {u:i for i,u in enumerate(vocab)}\n",
        "#print(char2id.items())\n",
        "id2char = np.array(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4aZg2SfwY1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_as_int = np.array([char2id[x] for x in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr44K4iMxGwr",
        "colab_type": "code",
        "outputId": "f0212fbc-98af-4070-e1aa-e1fc4f032f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(text_as_int[:20])\n",
        "print(id2char[18])\n",
        "print(id2char[1])\n",
        "print(id2char[15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56]\n",
            "F\n",
            " \n",
            "C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIsRlSNByQTg",
        "colab_type": "text"
      },
      "source": [
        "Now we have an integer representation for each character. Notice that we mapped the character as indexes from 0 to `len(unique)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCGGI4ICxjcA",
        "colab_type": "code",
        "outputId": "53c064ab-37af-46ee-cf7c-902c9910fb1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2id, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2id[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5rXBBLCx1g9",
        "colab_type": "code",
        "outputId": "43016c33-7bc5-4838-f483-5c888af5ae2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em9oGtSjyw5k",
        "colab_type": "text"
      },
      "source": [
        "Given a character, or a sequence of characters, what is the most probable next character? This is the task we're training the model to perform. The input to the model will be a sequence of characters, and we train the model to predict the output—the following character at each time step.\n",
        "\n",
        "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2DglOt2y2Ht",
        "colab_type": "text"
      },
      "source": [
        "####Create training examples and targets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLK4BkG7y1gV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt1dTsqNyeWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyrR4fXuWtYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOTY4kIyWtdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6leN4VIqWxNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmJpMJg2WxRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EM38jw0WxgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}