{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course_02_Week_03.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DujdShFQYsgb",
        "XkxVUixP5mAr",
        "Q4QESO7Bak0y",
        "6qbqM-XBcO-u",
        "xqPcQpAQmcmI",
        "14Qpebihfe4q",
        "llYNHpXWfWtu",
        "i-nJ9nAvzgzh",
        "M7eD9IIE_4uB",
        "GUffShbBQbt1",
        "BBnz-AbsaWWo",
        "RwQc5jcqLLt4",
        "ORx3Wvg5PlM0",
        "KNYprdFVbUCU",
        "l6UXgtV_LFiu",
        "lmml--8OIZe4",
        "H4xcMtnT_zZl",
        "uYbN2HV5KfEb",
        "WbviAcnVEXcJ",
        "8YUVdVHqL6a7",
        "dQvK09TQMBxM",
        "N9cYg6DIkGwt",
        "JGcmCy_48gsk",
        "nBPT3LkV_lNy",
        "8LqDCo5CkYn0",
        "RUv6s-tVa4hl",
        "iSp6MB7ZhT_s",
        "M0IOEc-2j8lr",
        "PlWZawLbkAcG",
        "e6R2FzbdkGac",
        "RJqosIAxiHiZ",
        "XSAwCBfoi-vv",
        "tKjE0PKxjWP-",
        "xnB4XpxOjZJO",
        "jnRxgMtijirE",
        "dGTtjG_NjrM-",
        "8FDuzLxBSfqX",
        "qNMhA-j1YlFt",
        "TXialC-1cfu4",
        "ArJdiELJcqLJ",
        "o3nva6jaGi5l",
        "x2LfQVEbGREX",
        "THKD1GKTL62Y",
        "a8jRYSeKM9RY",
        "iqQwcabWhkIu",
        "aVgJOwCwstHt",
        "3BWv-MA8fnI2",
        "saFOXyjTp7WU",
        "HA_JNeUfqQHQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZQHJBmlaBwM",
        "colab_type": "text"
      },
      "source": [
        "#Course 02\n",
        "Convolutional Neural Networks in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqQwcabWhkIu",
        "colab_type": "text"
      },
      "source": [
        "##Week03 Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVgJOwCwstHt",
        "colab_type": "text"
      },
      "source": [
        "### Model with the Transfer Learning : With and Without DropOut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HleyMUZhkYK",
        "colab_type": "text"
      },
      "source": [
        "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVsAmU0zhxKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow --upgrade --force-reinstall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZazp6NhxPz",
        "colab_type": "code",
        "outputId": "b2b85bb8-ec2a-41b4-fff3-607da35fa0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yambCyGpWayb",
        "colab_type": "code",
        "outputId": "aee6eafe-2142-4de4-966b-be2622425048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# load the weights first for the model:\n",
        "import os \n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-02 15:25:18--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  28%[====>               ]  24.01M   120MB/s               \r        /tmp/incept  66%[============>       ]  56.01M   129MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   159MB/s    in 0.5s    \n",
            "\n",
            "2020-04-02 15:25:19 (159 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXdse-dKhxOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "                                 input_shape = (150,150,3),\n",
        "                                 include_top = False,\n",
        "                                 weights = None )\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Lets freeze the layers from re-training :\n",
        "\n",
        "for layers in pre_trained_model.layers:\n",
        "  layers.trainable = False\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q82Fb5P8hklh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Now i decide to take the output from the layer names : mixed7 which you will find in the summary and then I will use that to fir to my neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqDjU_ZChxG2",
        "colab_type": "code",
        "outputId": "83528703-a9dd-4afb-d068-5b4b59ab35be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('Last Layer output shape : ',last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last Layer output shape :  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idn5KW7qbOni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets now feed the output from this layer :\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output\n",
        "x = tf.keras.layers.Flatten()(last_output)\n",
        "x = tf.keras.layers.Dense(units = 1024 , activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(units = 1 , activation = 'sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(pre_trained_model.input , x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX7-nRv0hvTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = 0.0001),\n",
        "              metrics = ['accuracy'],\n",
        "              loss = 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsskUa7CcwKg",
        "colab_type": "code",
        "outputId": "7bfb0e41-77ef-4f51-e679-213a9fdbdc08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Now lets download the cat-vs-dog dataset to proceed further :\n",
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-02 10:34:33--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  36%[======>             ]  23.72M   119MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   193MB/s    in 0.3s    \n",
            "\n",
            "2020-04-02 10:34:33 (193 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-XakTc9cwWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the file cotents :\n",
        "\n",
        "import os \n",
        "import zipfile\n",
        "\n",
        "zipped_folder_path = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(zipped_folder_path,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6451WZUcwbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzipped file already has the train test and then cats dogs split :\n",
        "\n",
        "# lets now create the directories to be used later ;\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir,'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir,'cats')\n",
        "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dogs_fnames = os.listdir(train_dogs_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRC5a0yrcwZn",
        "colab_type": "code",
        "outputId": "6f166c83-4b05-4e6d-8549-02831abbddf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Now lets create the data pipelines :\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale = 1./255,\n",
        "                  rotation_range = 40,\n",
        "                  width_shift_range = 0.2,\n",
        "                  height_shift_range = 0.2,\n",
        "                  shear_range = 0.2,\n",
        "                  zoom_range = 0.2,\n",
        "                  horizontal_flip = True,\n",
        "                  fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                    directory = train_dir,\n",
        "                                    target_size = (150,150),\n",
        "                                    batch_size = 20,\n",
        "                                    class_mode = 'binary',\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "                   rescale = 1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                                   directory = validation_dir,\n",
        "                                   target_size = (150,150),\n",
        "                                   batch_size = 20,\n",
        "                                   class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqOaPTtjgvwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets fit the model :\n",
        "\n",
        "history = model.fit_generator(\n",
        "                    train_generator,\n",
        "                    steps_per_epoch = 100,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps = 50,\n",
        "                    verbose = 1,\n",
        "                    epochs = 20\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34kOhufZhmG1",
        "colab_type": "code",
        "outputId": "1cb197e4-edb3-40c4-ca64-cec5fcd9f7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTbRhqUPbkr6",
        "colab_type": "text"
      },
      "source": [
        "So clearly the model is overfitting the training data !!! So now we have already been using the data augmentation ..what else can we do ? \n",
        "\n",
        "Actually because of the complexity of the model the augmentation is also not able to control the overfitting . So what we can do is we can actually reduce the complexity by intrducing the concept of **DROPOUT**\n",
        "\n",
        "Lets add the dropout layer and compile and retrain to see the changes !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06y2krq6j7RH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets now feed the output from this layer :\n",
        "\n",
        "\n",
        "x = tf.keras.layers.Flatten()(last_output)\n",
        "x = tf.keras.layers.Dense(units = 1024 , activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(units = 1 , activation = 'sigmoid')(x)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Model(pre_trained_model.input , x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2cLoE8sbiDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = 0.0001),\n",
        "              metrics = ['accuracy'],\n",
        "              loss = 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EBro67Pbb0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets fit the model :\n",
        "\n",
        "history = model.fit_generator(\n",
        "                    train_generator,\n",
        "                    steps_per_epoch = 100,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps = 50,\n",
        "                    verbose = 1,\n",
        "                    epochs = 20\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmtetacdcakF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxmOJIYgesEY",
        "colab_type": "text"
      },
      "source": [
        "Dropout does help because \"Neighbour Neurons can have similar weights and thus can skew the final training \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BWv-MA8fnI2",
        "colab_type": "text"
      },
      "source": [
        "###Exercise 3 - Horses vs. humans using Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohjjt_SLsmFB",
        "colab_type": "text"
      },
      "source": [
        "This week your exercise will be to apply what you've learned about Transfer Learning to see if you can increase training accuracy for Horses v Humans. To avoid crazy overfitting, your validation set accuracy should be around 95% if you do it right!\n",
        "\n",
        "Your training should automatically stop once it reaches this desired accuracy.\n",
        "\n",
        "Let's now use Transfer Learning to increase the training accuracy for Horses v Humans!\n",
        "\n",
        "NOTE: Please do not alter any of the provided code in the exercise. Only add your own code where indicated. Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position. Please use the provided epoch values when training. Once you have completed your notebook assignment and received a final score, please save your notebook, run the final cell, and close your Jupyter Workspace. This will help optimize your Jupyter workspace performance for future assessments. Please note that this step will shut down your kernel, so it is important to save your work in advance of completing this step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tto76NEfp9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
        "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
        "# ATTENTION: Please use the provided epoch values when training.\n",
        "\n",
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from os import getcwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftvCC-Rzg467",
        "colab_type": "code",
        "outputId": "abb26bbf-5272-4410-e526-58d3797b5bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "# load the weights first for the model:\n",
        "import os \n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "path_inception = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "local_weights_file = path_inception\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "                                input_shape = (150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None\n",
        "                               )# Your Code Here\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-02 15:40:30--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  19%[==>                 ]  16.01M  54.9MB/s               \r        /tmp/incept  57%[==========>         ]  48.01M  76.3MB/s               \r       /tmp/incepti  66%[============>       ]  56.01M  48.5MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M  67.7MB/s    in 1.2s    \n",
            "\n",
            "2020-04-02 15:40:31 (67.7 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwJ1Op42ih3l",
        "colab_type": "code",
        "outputId": "65156627-692f-4668-c6fa-2ebf7c0216b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output# Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsIabCyhjM5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.97):\n",
        "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZj9e2S7jPAa",
        "colab_type": "code",
        "outputId": "65a97b25-4fe8-4ca8-dfca-c180191caead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(units = 1024,activation = 'relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (units = 1 , activation = 'sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYsBGvfnkFDL",
        "colab_type": "code",
        "outputId": "a5cf6481-ced0-45c8-9567-b9ae503a7ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '/tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-02 16:11:58--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "\r/tmp/horse-or-human   0%[                    ]       0  --.-KB/s               \r/tmp/horse-or-human  40%[=======>            ]  58.22M   291MB/s               \r/tmp/horse-or-human  80%[===============>    ] 115.04M   287MB/s               \r/tmp/horse-or-human 100%[===================>] 142.65M   272MB/s    in 0.5s    \n",
            "\n",
            "2020-04-02 16:11:59 (272 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-04-02 16:12:02--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-02 16:12:02 (289 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdysjdG_k40X",
        "colab_type": "code",
        "outputId": "77a98e27-4096-4f7f-f321-1b275664ef44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir,'horses')# Your Code Here\n",
        "train_humans_dir = os.path.join(train_dir,'humans')# Your Code Here\n",
        "\n",
        "validation_horses_dir = os.path.join(validation_dir,'horses')# Your Code Here\n",
        "validation_humans_dir = os.path.join(validation_dir,'humans')# Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)# Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)# Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)# Your Code Here\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-IOgV59mn9O",
        "colab_type": "code",
        "outputId": "ada68499-0824-49ca-fa4d-b8c1da06dc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                rescale = 1.0/255.,\n",
        "                rotation_range = 40,\n",
        "                width_shift_range = 0.2,\n",
        "                height_shift_range = 0.2,\n",
        "                shear_range = 0.2,\n",
        "                horizontal_flip = True,\n",
        "                fill_mode ='nearest'\n",
        ")\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                              directory =  train_dir,\n",
        "                              target_size = (150,150),\n",
        "                              batch_size = 13,\n",
        "                              class_mode = 'binary'\n",
        ")     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( \n",
        "                               directory = validation_dir,\n",
        "                               target_size = (150,150),\n",
        "                               batch_size = 8,\n",
        "                               class_mode = 'binary'   \n",
        ")\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH-S5wO6n9Wb",
        "colab_type": "code",
        "outputId": "bac44b30-d9c2-4077-a7d7-a5c4e53ae29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 97% accuracy\n",
        "\n",
        "\n",
        "# callbacks = # Your Code Here\n",
        "# history = model.fit_generator(# Your Code Here (set epochs = 3))\n",
        "\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "                              train_generator,\n",
        "                              steps_per_epoch = 79,\n",
        "                              validation_data = validation_generator,\n",
        "                              validation_steps = 32,\n",
        "                              epochs = 3,\n",
        "                              verbose = 2,\n",
        "                              callbacks = [callbacks]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 79 steps, validate for 32 steps\n",
            "Epoch 1/3\n",
            "\n",
            "Reached 97.0% accuracy so cancelling training!\n",
            "79/79 - 12s - loss: 0.0558 - accuracy: 0.9825 - val_loss: 4.2100e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh2_UzblpxRN",
        "colab_type": "code",
        "outputId": "9ceb1fce-17c5-4f51-96b3-9073b90206bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saFOXyjTp7WU",
        "colab_type": "text"
      },
      "source": [
        "###### Submission Instructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w61bMe5p8jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now click the 'Submit Assignment' button above."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA_JNeUfqQHQ",
        "colab_type": "text"
      },
      "source": [
        "##### When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Q-UCGvp-bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%javascript\n",
        "# <!-- Save the notebook -->\n",
        "# IPython.notebook.save_checkpoint();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-anbfieqUn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%javascript\n",
        "# IPython.notebook.session.delete();\n",
        "# window.onbeforeunload = null\n",
        "# setTimeout(function() { window.close(); }, 1000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqPD6_4msdkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}